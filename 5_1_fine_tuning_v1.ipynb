{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acb9tYDziDHp"
      },
      "source": [
        "## **1: Pre-requisitos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: como ver la version del python\n",
        "\n",
        "import sys\n",
        "sys.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "D19URfuIlW-J",
        "outputId": "5e68f06d-d002-4f0f-9d19-8bf6e98823b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n"
      ],
      "metadata": {
        "id": "owBytfRQmRps",
        "outputId": "10234b9e-f525-4f80-bcc4-3d313e1a3f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1. Instalación de Dependencias**"
      ],
      "metadata": {
        "id": "xb7gMjncV9pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala todas las dependencias necesarias\n",
        "# !pip install torch==2.0.1+cu118 transformers==4.44.2\n",
        "# !pip install --upgrade transformers==4.45.2 accelerate==1.0.1\n",
        "# !pip install mlflow==2.16.0 pyngrok==7.2.0\n",
        "# peft==0.13.2"
      ],
      "metadata": {
        "id": "k-vleEe_SO8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate==0.4.0 rouge-score==0.1.2\n",
        "!pip install datasets==3.0.1 #wandb==0.13.1\n",
        "!pip install -U bitsandbytes==0.41.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWuDQPV4M9n3",
        "outputId": "47d4b2a2-3f6c-4a9b-ce1a-007d2652417b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate==0.4.0\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting rouge-score==0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.4.0)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (1.26.4)\n",
            "Collecting dill (from evaluate==0.4.0)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (4.66.6)\n",
            "Collecting xxhash (from evaluate==0.4.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.0) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0) (24.1)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (17.0.0)\n",
            "Collecting dill (from evaluate==0.4.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate==0.4.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.0) (2024.8.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score==0.1.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score==0.1.2) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score==0.1.2) (2024.9.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.0) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (4.0.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.0.0->evaluate==0.4.0) (0.2.0)\n",
            "Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=06c28a38580b3937a2a8bcbcf1da35e622b5b26283a73f15186a1a773ff162d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: xxhash, fsspec, dill, rouge-score, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.0 fsspec-2024.9.0 multiprocess-0.70.16 responses-0.18.0 rouge-score-0.1.2 xxhash-3.5.0\n",
            "Collecting datasets==3.0.1\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.70.16)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.1)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.1) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.1) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets==3.0.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.1) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.1) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.1) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==3.0.1) (0.2.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.1.0\n",
            "    Uninstalling datasets-3.1.0:\n",
            "      Successfully uninstalled datasets-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 fsspec-2024.6.1\n",
            "Collecting bitsandbytes==0.41.3\n",
            "  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.41.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Versiones de Paquetes ===\")\n",
        "\n",
        "# torch\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"torch: {torch.__version__}\")\n",
        "except:\n",
        "    print(\"torch: No instalado\")\n",
        "\n",
        "# evaluate\n",
        "try:\n",
        "    import evaluate\n",
        "    print(f\"evaluate: {evaluate.__version__}\")\n",
        "except:\n",
        "    print(\"evaluate: No instalado\")\n",
        "\n",
        "# pandas\n",
        "try:\n",
        "    import pandas as pd\n",
        "    print(f\"pandas: {pd.__version__}\")\n",
        "except:\n",
        "    print(\"pandas: No instalado\")\n",
        "\n",
        "# numpy\n",
        "try:\n",
        "    import numpy as np\n",
        "    print(f\"numpy: {np.__version__}\")\n",
        "except:\n",
        "    print(\"numpy: No instalado\")\n",
        "\n",
        "# pytz\n",
        "try:\n",
        "    import pytz\n",
        "    print(f\"pytz: {pytz.__version__}\")\n",
        "except:\n",
        "    print(\"pytz: No instalado\")\n",
        "\n",
        "# wandb\n",
        "try:\n",
        "    import wandb\n",
        "    print(f\"wandb: {wandb.__version__}\")\n",
        "except:\n",
        "    print(\"wandb: No instalado\")\n",
        "\n",
        "# huggingface_hub\n",
        "try:\n",
        "    import huggingface_hub\n",
        "    print(f\"huggingface_hub: {huggingface_hub.__version__}\")\n",
        "except:\n",
        "    print(\"huggingface_hub: No instalado\")\n",
        "\n",
        "# transformers\n",
        "try:\n",
        "    import transformers\n",
        "    print(f\"transformers: {transformers.__version__}\")\n",
        "except:\n",
        "    print(\"transformers: No instalado\")\n",
        "\n",
        "# datasets\n",
        "try:\n",
        "    import datasets\n",
        "    print(f\"datasets: {datasets.__version__}\")\n",
        "except:\n",
        "    print(\"datasets: No instalado\")\n",
        "\n",
        "# peft\n",
        "try:\n",
        "    import peft\n",
        "    print(f\"peft: {peft.__version__}\")\n",
        "except:\n",
        "    print(\"peft: No instalado\")\n",
        "\n",
        "# scikit-learn\n",
        "try:\n",
        "    import sklearn\n",
        "    print(f\"scikit-learn: {sklearn.__version__}\")\n",
        "except:\n",
        "    print(\"scikit-learn: No instalado\")\n",
        "\n",
        "# accelerate\n",
        "try:\n",
        "    import accelerate\n",
        "    print(f\"accelerate: {accelerate.__version__}\")\n",
        "except:\n",
        "    print(\"accelerate: No instalado\")\n",
        "\n",
        "# bitsandbytes (caso especial)\n",
        "try:\n",
        "    import bitsandbytes\n",
        "    import subprocess\n",
        "    result = subprocess.run(['pip', 'show', 'bitsandbytes'], capture_output=True, text=True)\n",
        "    version = [line for line in result.stdout.split('\\n') if 'Version:' in line]\n",
        "    version = version[0].split('Version: ')[1] if version else \"Versión desconocida\"\n",
        "    print(f\"bitsandbytes: {version}\")\n",
        "except:\n",
        "    print(\"bitsandbytes: No instalado\")\n",
        "\n",
        "# tqdm\n",
        "try:\n",
        "    import tqdm\n",
        "    print(f\"tqdm: {tqdm.__version__}\")\n",
        "except:\n",
        "    print(\"tqdm: No instalado\")\n",
        "\n",
        "# Bibliotecas estándar (estas vienen con Python)\n",
        "print(\"\\n=== Bibliotecas Estándar ===\")\n",
        "print(\"subprocess: Instalado (biblioteca estándar)\")\n",
        "print(\"getpass: Instalado (biblioteca estándar)\")\n",
        "print(\"datetime: Instalado (biblioteca estándar)\")\n",
        "print(\"re: Instalado (biblioteca estándar)\")\n",
        "print(\"glob: Instalado (biblioteca estándar)\")\n",
        "print(\"pickle: Instalado (biblioteca estándar)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "709hZzVHSqSb",
        "outputId": "caf40bbe-7367-42c6-dba4-c8d50eda8cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Versiones de Paquetes ===\n",
            "torch: 2.5.0+cu121\n",
            "evaluate: 0.4.0\n",
            "pandas: 2.2.2\n",
            "numpy: 1.26.4\n",
            "pytz: 2024.2\n",
            "wandb: 0.18.5\n",
            "huggingface_hub: 0.24.7\n",
            "transformers: 4.44.2\n",
            "datasets: 3.0.1\n",
            "peft: 0.13.2\n",
            "scikit-learn: 1.5.2\n",
            "accelerate: 0.34.2\n",
            "bitsandbytes: 0.41.3\n",
            "tqdm: 4.66.6\n",
            "\n",
            "=== Bibliotecas Estándar ===\n",
            "subprocess: Instalado (biblioteca estándar)\n",
            "getpass: Instalado (biblioteca estándar)\n",
            "datetime: Instalado (biblioteca estándar)\n",
            "re: Instalado (biblioteca estándar)\n",
            "glob: Instalado (biblioteca estándar)\n",
            "pickle: Instalado (biblioteca estándar)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el archivo requirements.txt\n",
        "requirements = \"\"\"torch==2.5.0+cu121\n",
        "evaluate==0.4.0\n",
        "pandas==2.2.2\n",
        "numpy==1.26.4\n",
        "pytz==2024.2\n",
        "wandb==0.18.5\n",
        "huggingface_hub==0.24.7\n",
        "transformers==4.44.2\n",
        "datasets==3.0.1\n",
        "peft==0.13.2\n",
        "scikit-learn==1.5.2\n",
        "accelerate==0.34.2\n",
        "bitsandbytes==0.41.3\n",
        "tqdm==4.66.6\n",
        "\"\"\"\n",
        "\n",
        "# Escribir en el archivo\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(requirements)\n",
        "\n",
        "print(\"Contenido del archivo requirements.txt:\")\n",
        "print(requirements)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xZOjvQyTj34",
        "outputId": "13285db0-58d4-4d14-ba95-c4ad34e2eb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenido del archivo requirements.txt:\n",
            "torch==2.5.0+cu121\n",
            "evaluate==0.4.0\n",
            "pandas==2.2.2\n",
            "numpy==1.26.4\n",
            "pytz==2024.2\n",
            "wandb==0.18.5\n",
            "huggingface_hub==0.24.7\n",
            "transformers==4.44.2\n",
            "datasets==3.0.1\n",
            "peft==0.13.2\n",
            "scikit-learn==1.5.2\n",
            "accelerate==0.34.2\n",
            "bitsandbytes==0.41.3\n",
            "tqdm==4.66.6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTAHBBhiMDv"
      },
      "source": [
        "### **1.2: Importación de Librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-24T02:42:16.181188Z",
          "iopub.status.busy": "2024-09-24T02:42:16.179331Z",
          "iopub.status.idle": "2024-09-24T02:45:02.627023Z",
          "shell.execute_reply": "2024-09-24T02:45:02.618231Z",
          "shell.execute_reply.started": "2024-09-24T02:42:16.181111Z"
        },
        "id": "GroUt76ZnX3q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "import torch\n",
        "import evaluate\n",
        "import subprocess\n",
        "import getpass # Para autenticarse en HF\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pytz # Zona horaria\n",
        "import wandb\n",
        "import re\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer #, AutoModelForSeq2SeqLM\n",
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback, TrainerCallback, GenerationConfig, AutoConfig\n",
        "from datasets import load_dataset, Dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from peft import PeftModel, PeftConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "from accelerate import Accelerator\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BitsAndBytesConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica que torch pueda ver la GPU\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Memory allocated:\", torch.cuda.memory_allocated(0))\n",
        "    print(\"Memory reserved:\", torch.cuda.memory_reserved(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-CtPXAHX_yW",
        "outputId": "a0b202c2-e317-41b5-fc6b-143663ad5d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Current device: 0\n",
            "Device name: Tesla T4\n",
            "Memory allocated: 0\n",
            "Memory reserved: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arqE2SXLWTFv",
        "outputId": "fdbb27ac-c2fe-4878-f74d-690bd5fd54f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2: Configuración**"
      ],
      "metadata": {
        "id": "cgC4eOh4U7jV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Definicion de variables**"
      ],
      "metadata": {
        "id": "D4VYyHiHqESe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_model_name(name):\n",
        "    \"\"\"Limpia el nombre del modelo, eliminando caracteres no permitidos para Hugging Face Hub.\"\"\"\n",
        "    # Reemplazar espacios y puntos con guiones bajos\n",
        "    name = name.replace(\" \", \"_\").replace(\".\", \"_\")\n",
        "    # Eliminar cualquier otro carácter especial no permitido\n",
        "    name = re.sub(r'[^a-zA-Z0-9_-]', '', name)\n",
        "    return name"
      ],
      "metadata": {
        "id": "iMvhxHvIt_FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_MODEL_NAME = \"Qwen/Qwen2.5-1.5B\"  # Asegúrate de seleccionar el modelo adecuado #Qwen/Qwen2.5-1.5B / meta-llama/Llama-3.2-1B / microsoft/phi-1\n",
        "MODEL_NAME = BASE_MODEL_NAME.split('/')[-1]\n",
        "CLEAN_MODEL_NAME = clean_model_name(MODEL_NAME)\n",
        "print(MODEL_NAME)\n",
        "print(CLEAN_MODEL_NAME)\n",
        "\n",
        "FILE_PATH = '/content/drive/MyDrive/ColabNotebooks/Data/dataset1k.tsv'\n",
        "FILE_NAME = os.path.splitext(os.path.basename(FILE_PATH))[0]\n",
        "print(FILE_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGShJQyMqNAk",
        "outputId": "8fade4b0-9b80-4a32-d9db-b0af5bcd39ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen2.5-1.5B\n",
            "Qwen2_5-1_5B\n",
            "dataset1k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2. Login Hugging Face**"
      ],
      "metadata": {
        "id": "5VXgfXLAjV6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_huggingface_hub_token():\n",
        "    \"\"\"Configura el token para Hugging Face Hub solicitándolo al usuario y verificando su existencia.\"\"\"\n",
        "    if \"HUGGING_FACE_HUB_TOKEN\" in os.environ:\n",
        "        print(\"Token ya configurado.\")\n",
        "    else:\n",
        "        token = getpass.getpass(\"Token: \") #\n",
        "        if token:  # Verificar que el token no esté vacío\n",
        "            os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = token\n",
        "            print(\"Token configurado exitosamente.\")\n",
        "        else:\n",
        "            raise ValueError(\"No se ingresó un token válido.\")\n",
        "\n",
        "# Uso de la función\n",
        "try:\n",
        "    set_huggingface_hub_token()\n",
        "except ValueError as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFjnJX3i9FYN",
        "outputId": "4ea7aa28-c002-413d-e0db-e673b2924f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: ··········\n",
            "Token configurado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.secret(\"HUGGING_FACE_HUB_TOKEN\")"
      ],
      "metadata": {
        "id": "U-bj6tGEz12o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3. Configuración del Modelo**"
      ],
      "metadata": {
        "id": "nFg6qm9Ml2AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    \"\"\"Configura y retorna el dispositivo basado en la disponibilidad de CUDA.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Usando dispositivo: {device}\")\n",
        "    return device"
      ],
      "metadata": {
        "id": "OHTsZP5NYrO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device():\n",
        "    \"\"\"Configura y retorna el dispositivo para entrenamiento basado en la disponibilidad de CUDA.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"CUDA está disponible. Usando GPU.\")\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        print(\"CUDA no está disponible. Usando CPU.\")\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "def load_model_and_tokenizer(base_model_name):\n",
        "    \"\"\"Carga un modelo y un tokenizador, manejando posibles excepciones durante la carga.\"\"\"\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map=\"auto\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True, clean_up_tokenization_spaces=True)\n",
        "        print(\"Modelo y tokenizador cargados exitosamente.\")\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar el modelo o el tokenizador: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Uso de las funciones\n",
        "device = set_device()\n",
        "model_base2, tokenizer2 = load_model_and_tokenizer(BASE_MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZYh-Q5M8i6o",
        "outputId": "255932dd-7ac3-49ad-c11f-1c2d7e994dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA está disponible. Usando GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo y tokenizador cargados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_optimized(base_model_name, use_4bit=False):\n",
        "    try:\n",
        "        if use_4bit:\n",
        "            # Código 1 con mejoras\n",
        "            compute_dtype = torch.float16\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True  # Asegúrate de que esta opción esté correctamente definida\n",
        "            )\n",
        "        else:\n",
        "            # Código 2 con mejoras\n",
        "            compute_dtype = torch.bfloat16\n",
        "            quantization_config = None  # Para evitar que se pase un objeto no necesario\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            base_model_name,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=compute_dtype,\n",
        "            offload_folder=\"./offload\"\n",
        "            # low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        # Optimizaciones comunes\n",
        "        #model.gradient_checkpointing_enable()\n",
        "        #model.enable_input_require_grads()\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "model_base, tokenizer = load_model_optimized(BASE_MODEL_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "2f8a79b24c284390982e79d683fed0d8",
            "afe5385cb6794fbe82e0df873d938880",
            "b405a63270ca49ae87c956213fa4d9b7",
            "7b9146884f27482d9551ebed28c16ca4",
            "af7ee967d2ee487a9943b6c54bdc5561",
            "bc8974736fb040e28ff15c1467609e23",
            "795581b5c9694682af2492fc33440d3f",
            "1e688cbadc4b404b85cbc19c0c8db692",
            "a9a84f85386f41558cabaa8da1302b32",
            "4925a2aa520d4149a345c8a067bda554",
            "70f6b49d096e465d80b9a6adb2c27ab0",
            "9162697e0bf848ba80bd3dfade0fadea",
            "f8fc71bde09847a7a870309e29cc6732",
            "9bd6dbdea24c485e9aafbc140c513b75",
            "5c838d4d32344f1abe79d42bf5c826d7",
            "3db2007080e24384812a5c9d0e4ef309",
            "506bf371135e4a36a64b17379440728f",
            "6afe4be05f3e4a19a5d949f37da752a4",
            "b7b7e7fd77454199bc899dde2bcb593a",
            "289c1ca2bc564f7b809b1bb4ca3a5471",
            "1376dc6a1ceb433082559ba1819be37d",
            "608b2c36b38a4ed3981af56dfcfba958",
            "c8d30bf3acc44a9cb529063deab5189e",
            "471dc584ec8945cdb541cc5e58c2b9db",
            "d096bfc66f7d41ada89da114a300781f",
            "88bb355c83b242aa96c6c11fb229e91f",
            "4126f2832516449f87babe0eb2fa01da",
            "d8027ee8e8a546e5853c8cdb0893a3ef",
            "286174fa97cc4b50b3a88e3e9d019fe7",
            "931f5d8eda08404188e2afde2a0a4bb2",
            "d5d7e16395ac43ab9236a31d21d0d9a0",
            "aa4155e7bcdb4f68a619c15bfffb542f",
            "4c7d6a93c3814d2ba104e0ec50e9ddb9",
            "49a8c962bebf463ebebd8162b341b94e",
            "4a2738cf3c8f4b0dae541abb5686b6cf",
            "406fe412fbb1432a82112d8333759e12",
            "d1a6e62adb0746a1a6d539536d77d697",
            "c69a61fe528a4bfcb5c3b854dbd910ea",
            "ac408625cd9f46e5a17d27ca858eec4d",
            "4b57743c65a349cba4ed46ad3c661402",
            "da0a166c8661440e90dd1e1badccfad3",
            "c5df55fc6f344f389a4017526b0b239e",
            "9206bbd085b648939a9c024e20a8c11c",
            "3871e3cefbec4a7083770333a9f4b533",
            "87455c7143c34b73ad91f6fe6a454ceb",
            "92d136779e9d46fb9338120d4209c741",
            "726ab22e186c469fa7218e331682b0e4",
            "3c705724b2a04e5ea504fdbf59cc2ec4",
            "db3b0ef9a885426bbb7e0e8c73302ecd",
            "c6767717eac94f518d936b20a4de8502",
            "3a4dbbc95aa44c2f88195bc6b96ba683",
            "5b8c48b7e89245c0aab431f61c739c84",
            "fd2ccefd72c44d8c9b0a2c672455a756",
            "c1431824d0764669a5fefd7dc002f483",
            "ef09dcce388c45e69ff105ab64ddac9b",
            "da02f5884d804b34a99bb75398cfdcfa",
            "dc4cd561f9864c6e956c1883aca2258f",
            "050166e9561741b4bdabf7fec1da8e07",
            "fb1d9a0bdc2e4984b93c726fc6d7c19d",
            "5a49df75413f446ab18a0fc5a2a5f890",
            "fd8980c9a71a4bd89c2fc2afc607cab1",
            "765f25121d7349b4a4c7bc433feacfad",
            "73dfa40baadb4c05a6558cf43f49c832",
            "cc6dd44637674318b4ba1a53abd364bb",
            "c9e95d48cb68463fa194d01e18048f98",
            "5c1154b1d6af4fb780d22fb3f4251ab7",
            "866bf815167944d5b9e82cfcf70738f9",
            "a6f7827e3aed414f8bcb978fca702564",
            "466db3b0159b4c8392094541ce7367b8",
            "5f6b57fca7d04dd8a895243529b42579",
            "2883f1ae72154d4b85c0c251650b286f",
            "d4c8f010e3f346a99990f5af779c1d5a",
            "1b4b6a16f45b4c6699d8e9c5f4614604",
            "5d57e893bb24420bbf2dc274cdfe6075",
            "551b527cad3b493aa2a1ed07493aa197",
            "654a64d109b6460fab7102805d558d16",
            "1aa4140d9e63443f8d3e1ece80972008",
            "5bf7afef981d49b68cb0133e8846ec36",
            "e5f45e4305144133b73324965ee1f33f",
            "b042240560dc4adf926e31a4cc64a8e2",
            "1911798d527741f882d467ddaf3eb069",
            "047ededd5cbc405cbcab294264e3c19f",
            "ffb782c5bcf14b93a21202bdbc07d1cb",
            "118731b8958745328c16734a9a4a2e63",
            "1ff24fed795b44588a6df8e0f20b56f1",
            "d8133f21a51a47dbb20436d5c61f7016",
            "bfbecc94dfa244a3a35382379283fce6",
            "7adc595144e54d0eb0bd322adf98250b",
            "29941c21e2fa4a6ea8a135c476213d0a",
            "821dec6ccca043dcba5ecf69e67b80b5",
            "e028c6b5e2ba48efaf6ff7c30850e4c0",
            "2c7f3391e6114109ba533ba3ba004444",
            "f7f2135178a34bbfa65b463823c3779c",
            "4e197c9cb56b4043ac15757aa42642cb",
            "3153f4c473254fb4adbc713ed0495b2a",
            "2aedce3328624c688b5a660401a024c1",
            "c5f5696c995f46ef925f7d501da51d56",
            "95038a08530d4d0e8c84926edafa5dfb",
            "e1699a5436bc4961b2d3770fa9e01ce1",
            "489f86ca168c421c8313858363af7f2d",
            "20e87f605f144302b9cbccc8447d5c0a",
            "d3c99db340e5487f9a59b5620e3986d8",
            "62077152b08640c2b6dd655948d3eaf3",
            "e1a44be87a6f4f99a7e09f2db4fa9df1",
            "898051fc804547749be8b15214142925",
            "da8c920861614255abd61603548033e6",
            "c83764d1f8264739bf55fa568ee05799",
            "d1d9b59bc6f0406690cef95e8f78ed6f",
            "803abcdae741487ca2b861848ceebd7c",
            "6f5e42ead5b74b1e8e5fbd528efa0136"
          ]
        },
        "id": "ugtNjgSeWy89",
        "outputId": "ae1fd440-fb4d-4eb2-891a-1e8ef4c45217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f8a79b24c284390982e79d683fed0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9162697e0bf848ba80bd3dfade0fadea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8d30bf3acc44a9cb529063deab5189e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49a8c962bebf463ebebd8162b341b94e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87455c7143c34b73ad91f6fe6a454ceb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da02f5884d804b34a99bb75398cfdcfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "866bf815167944d5b9e82cfcf70738f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bf7afef981d49b68cb0133e8846ec36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29941c21e2fa4a6ea8a135c476213d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "489f86ca168c421c8313858363af7f2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    print(f\"Número de GPUs disponibles: {num_gpus}\")\n",
        "    for i in range(num_gpus):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "else:\n",
        "    print(\"No hay GPUs disponibles.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL9qF2oRvxAS",
        "outputId": "a9650ac0-421b-48ca-c400-35d62d13f4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de GPUs disponibles: 1\n",
            "GPU 0: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cores = os.cpu_count()\n",
        "print(f\"Número de núcleos de CPU: {num_cores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfU480mP-vrr",
        "outputId": "5540ce24-52d5-4c17-c402-3ec13e2e0fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de núcleos de CPU: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Imprimir memoria de CPU usada\n",
        "print(f\"Memoria CPU: {psutil.virtual_memory().used / (1024 ** 3):.2f} GB\")\n",
        "\n",
        "# Imprimir uso de memoria en GPU\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZIXVq--zPuI",
        "outputId": "35e79e78-34b3-4341-8d97-cb8a9f3f8580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria CPU: 3.70 GB\n",
            "Mon Nov  4 05:21:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0              27W /  70W |   9585MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD_FLhkIia1K"
      },
      "source": [
        "## **3: Carga y Preparación del Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(FILE_PATH, sep='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n_9eXzgdmTMM",
        "outputId": "c7a59bc7-d533-46b7-9583-d995fbe0daed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         description  \\\n",
              "0  [\"('/**\\\\\\\\n     * This function selects tasks...   \n",
              "1  [\"('/**\\\\\\\\n     * This function selects tasks...   \n",
              "2  [\"('/**\\\\\\\\n     * This function selects tasks...   \n",
              "3  [\"('/**\\\\\\\\n     * This function selects tasks...   \n",
              "4  [\"('/**\\\\\\\\n     * This function selects tasks...   \n",
              "\n",
              "                                        focal_method  \\\n",
              "0  b'/**\\n     * This function selects tasks foll...   \n",
              "1  b'/**\\n     * This function selects tasks foll...   \n",
              "2  b'/**\\n     * This function selects tasks foll...   \n",
              "3  b'/**\\n     * This function selects tasks foll...   \n",
              "4  b'/**\\n     * This function selects tasks foll...   \n",
              "\n",
              "                                           test_case  \n",
              "0  @Test    public void testSelectZeroTasksWithZe...  \n",
              "1  @Test    public void testSelectTwoReadyAndOneD...  \n",
              "2  @Test    public void testSelectOneReadyAndTwoD...  \n",
              "3  @Test    public void testSelectThreeTasksOneOf...  \n",
              "4  @Test    public void testSelectZeroTasksWithZe...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9306e9e-c92a-4874-9b0d-abba57d78981\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>focal_method</th>\n",
              "      <th>test_case</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[\"('/**\\\\\\\\n     * This function selects tasks...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[\"('/**\\\\\\\\n     * This function selects tasks...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectTwoReadyAndOneD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[\"('/**\\\\\\\\n     * This function selects tasks...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectOneReadyAndTwoD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\"('/**\\\\\\\\n     * This function selects tasks...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectThreeTasksOneOf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[\"('/**\\\\\\\\n     * This function selects tasks...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9306e9e-c92a-4874-9b0d-abba57d78981')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9306e9e-c92a-4874-9b0d-abba57d78981 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9306e9e-c92a-4874-9b0d-abba57d78981');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b83330a5-c959-402b-88f9-609703e7782c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b83330a5-c959-402b-88f9-609703e7782c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b83330a5-c959-402b-88f9-609703e7782c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1016,\n  \"fields\": [\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 390,\n        \"samples\": [\n          \"['(\\\"/**\\\\\\\\\\\\\\\\n   * Returns a map from methods to return types, where the return types are not necessarily the\\\\\\\\\\\\\\\\n   * original return types of the methods. Consider this example:\\\\\\\\\\\\\\\\n   *\\\\\\\\\\\\\\\\n   * <pre>\\\\\\\\\\\\\\\\n   * &#64;AutoValue class {@code Foo<T>} {\\\\\\\\\\\\\\\\n   *   abstract T getFoo();\\\\\\\\\\\\\\\\n   *\\\\\\\\\\\\\\\\n   *   &#64;AutoValue.Builder\\\\\\\\\\\\\\\\n   *   abstract class {@code Builder<T>} {\\\\\\\\\\\\\\\\n   *     abstract Builder setFoo(T t);\\\\\\\\\\\\\\\\n   *     abstract {@code Foo<T>} build();\\\\\\\\\\\\\\\\n   *   }\\\\\\\\\\\\\\\\n   * }\\\\\\\\\\\\\\\\n   * </pre>\\\\\\\\\\\\\\\\n   *\\\\\\\\\\\\\\\\n   * We want to be able to check that the parameter type of {@code setFoo} is the same as the return\\\\\\\\\\\\\\\\n   * type of {@code getFoo}. But in fact it isn\\\\'t, because the {@code T} of {@code Foo<T>} is not\\\\\\\\\\\\\\\\n   * the same as the {@code T} of {@code Foo.Builder<T>}. So we create a parallel {@code Foo<T>}\\\\\\\\\\\\\\\\n   * where the {@code T} <i>is</i> the one from {@code Foo.Builder<T>}. That way the types do\\\\\\\\\\\\\\\\n   * correspond. This method then returns the return types of the given methods as they appear in\\\\\\\\\\\\\\\\n   * that parallel class, meaning the type given for {@code getFoo()} is the {@code T} of {@code\\\\\\\\\\\\\\\\n   * Foo.Builder<T>}.\\\\\\\\\\\\\\\\n   *\\\\\\\\\\\\\\\\n   * <p>We do the rewrite this way around (applying the type parameter from {@code Foo.Builder} to\\\\\\\\\\\\\\\\n   * {@code Foo}) because if we hit one of the historical Eclipse bugs with {@link Types#asMemberOf}\\\\\\\\\\\\\\\\n   * then {@link EclipseHack#methodReturnType} can use fallback logic, which only works for methods\\\\\\\\\\\\\\\\n   * with no arguments.\\\\\\\\\\\\\\\\n   *\\\\\\\\\\\\\\\\n   * @param methods the methods whose return types are to be rewritten.\\\\\\\\\\\\\\\\n   * @param sourceType the class containing those methods ({@code Foo} in the example).\\\\\\\\\\\\\\\\n   * @param targetType the class to translate the methods into ({@code Foo.Builder<T>}) in the\\\\\\\\\\\\\\\\n   *     example.\\\\\\\\\\\\\\\\n   */\\\", \\\\'\\\\')', '(\\\\'\\\\', \\\\'// What we\\\\\\\\\\\\'re doing is only valid if the type parameters are \\\"the same\\\". The check here even\\\\\\\\n\\\\')', \\\"('', '// requires the names to be the same. The logic would still work without that, but we impose\\\\\\\\n')\\\", \\\"('', '// that requirement elsewhere and it means we can check in this simple way.\\\\\\\\n')\\\"]\",\n          \"[\\\"('', '// Publish in all the existing single item streams.\\\\\\\\n')\\\", \\\"('', '// This could be improved publishing only in the items that changed. Maybe use DiffUtils?\\\\\\\\n')\\\"]\",\n          \"[\\\"('/**\\\\\\\\\\\\\\\\n     * Call this to try to give focus to a specific view or to one of its\\\\\\\\\\\\\\\\n     * descendants.\\\\\\\\\\\\\\\\n     *\\\\\\\\\\\\\\\\n     * A view will not actually take focus if it is not focusable ({@link #isFocusable} returns\\\\\\\\\\\\\\\\n     * false), or if it is focusable and it is not focusable in touch mode\\\\\\\\\\\\\\\\n     * ({@link #isFocusableInTouchMode}) while the device is in touch mode.\\\\\\\\\\\\\\\\n     *\\\\\\\\\\\\\\\\n     * See also {@link #focusSearch(int)}, which is what you call to say that you\\\\\\\\\\\\\\\\n     * have focus, and you want your parent to look for the next one.\\\\\\\\\\\\\\\\n     *\\\\\\\\\\\\\\\\n     * This is equivalent to calling {@link #requestFocus(int, Rect)} with arguments\\\\\\\\\\\\\\\\n     * {@link #FOCUS_DOWN} and <code>null</code>.\\\\\\\\\\\\\\\\n     *\\\\\\\\\\\\\\\\n     * @return Whether this view or one of its descendants actually took focus.\\\\\\\\\\\\\\\\n     */', '')\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focal_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 414,\n        \"samples\": [\n          \"b'/**\\\\n     * @return {@link SelectorFunction} which selects some size of wide aspect ratio (16:9).\\\\n     */'public static SelectorFunction<Collection<Size>, Size> wideRatio(SelectorFunction<Collection<Size>, Size> selector) {        return aspectRatio(16f / 9f, selector);    }\",\n          \"b'/**\\\\n     * Builds a {@link CaptureRequest} based on the builder parameters.\\\\n     *\\\\n     * @return The capture request.\\\\n     * @throws CameraAccessException If the camera device has been disconnected.\\\\n     */'CaptureRequest build() throws CameraAccessException {        validate();        return Request.create(this);    }\",\n          \"b'/**\\\\n     * @return {@code true} if selected lens position is available. {@code false} if it is not\\\\n     * available.\\\\n     */'public boolean isAvailable() {        return selectedLensPosition() != null;    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1010,\n        \"samples\": [\n          \"@Test    public void _26_TestSelectFilteredSingleColumnSpecifiedStatic()        throws ETSdkException    {        ETResponse<ETDataExtensionRow> response = ETDataExtension.select(client,                                                                         \\\"key=test1\\\",                                                                         \\\"LastName=Flintstone\\\",                                                                         \\\"LastName\\\");        testSelectFilteredSingleColumnSpecified(response);    }\",\n          \"@Test    public void testRandomGraphsS6() throws UnsupportedEncodingException, ExportException, ImportException {        GnpRandomGraphGenerator<Integer, DefaultEdge> gnp=new GnpRandomGraphGenerator<>(40, .55, 0, true);        for(int i=0; i<20; i++){            Graph<Integer, DefaultEdge> orig=new Pseudograph<>(DefaultEdge.class);            gnp.generateGraph(orig, new IntegerVertexFactory(), null);            String res = exportGraph(orig, Graph6Sparse6Exporter.Format.SPARSE6);            Graph<Integer, DefaultEdge> g = importGraph(res);            this.compare(orig, g);        }    }\",\n          \"@Test    public void testToString_whenPathString() {        String pathString = \\\"/bar/baz\\\";        Path p = new GlusterPath(mockFileSystem, pathString);        String filesystemString = \\\"gluster://127.0.2.1:foo\\\";        doReturn(filesystemString).when(mockFileSystem).toString();        assertEquals(pathString, p.toString());    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los últimos 20 registros\n",
        "df16 = df.tail(16)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQvMvlU-RAjz",
        "outputId": "84ef5c61-892b-4ebf-c81c-e941ad0684ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1016, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Limpiar Datos**"
      ],
      "metadata": {
        "id": "JuagcAu3BhIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'] = df['description'].str.replace(r'\\\\+n', '\\n', regex=True)\n",
        "#print(df.iloc[1,0])\n",
        "# Función optimizada con prints para depuración\n",
        "def clean_description(text):\n",
        "    \"\"\"Limpia la columna 'description' y muestra el progreso.\"\"\"\n",
        "\n",
        "    #print(f\"\\nTexto original:\\n{text}\")\n",
        "\n",
        "    # 1. Reemplaza caracteres especiales al inicio por '/*'\n",
        "    text = re.sub(r\"^[^\\w\\s]+\", \"/*\", text)\n",
        "\n",
        "    # 2. Reemplaza secuencia específica al inicio por '/*\\n'\n",
        "    text = re.sub(r\"^/\\*\\n\\*\\n\", \"/*\\n\", text)\n",
        "\n",
        "    # 3. Reemplaza caracteres especiales al final por '*/'\n",
        "    text = re.sub(r\"[^\\w\\s]+$\", \"*/\", text)\n",
        "\n",
        "    # 4. Elimina la secuencia \"', */\" al final de la cadena\n",
        "    text = re.sub(r\"', \\*/$\", \"\", text)\n",
        "\n",
        "    # 5. Remueve caracteres especiales excepto los permitidos\n",
        "    text = re.sub(r\"[^\\w\\s\\/\\*;@<>{}]\", \"\", text)\n",
        "\n",
        "    # 6. Reemplaza múltiples patrones con slashes y comas por vacío\n",
        "    text = re.sub(r\"(/\\s*,\\s*//|\\s*,\\s*,\\s*//|,\\s*,\\s*,\\s*,\\s*//)\", \"\", text)\n",
        "\n",
        "    # 7. Remover etiquetas <p> y </p>\n",
        "    text = re.sub(r'<p>|<\\/p>', '', text)  # Remueve <p> y </p>\n",
        "    #print(f\"\\nDespués de eliminar etiquetas <p> y </p>:\\n{text}\")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "ehxm4WRXKUZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la función a la columna 'description' para todos los registros\n",
        "df['description'] = df['description'].apply(clean_description)"
      ],
      "metadata": {
        "id": "8ZcSDCr_J9id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywsc-L3edfW2",
        "outputId": "f2bcba3c-cd28-4ce5-80a5-84835d45bada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         description  \\\n",
              "0  /*\\n     * This function selects tasks followi...   \n",
              "1  /*\\n     * This function selects tasks followi...   \n",
              "\n",
              "                                        focal_method  \\\n",
              "0  b'/**\\n     * This function selects tasks foll...   \n",
              "1  b'/**\\n     * This function selects tasks foll...   \n",
              "\n",
              "                                           test_case  \n",
              "0  @Test    public void testSelectZeroTasksWithZe...  \n",
              "1  @Test    public void testSelectTwoReadyAndOneD...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cda385c-47f2-4366-a8ed-93a68dad5dec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>focal_method</th>\n",
              "      <th>test_case</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectTwoReadyAndOneD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cda385c-47f2-4366-a8ed-93a68dad5dec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cda385c-47f2-4366-a8ed-93a68dad5dec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cda385c-47f2-4366-a8ed-93a68dad5dec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-37de03c6-d840-45b6-8d59-5e70b88d4c3b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-37de03c6-d840-45b6-8d59-5e70b88d4c3b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-37de03c6-d840-45b6-8d59-5e70b88d4c3b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1016,\n  \"fields\": [\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 390,\n        \"samples\": [\n          \"/*\\n   * Returns a map from methods to return types where the return types are not necessarily the\\n   * original return types of the methods Consider this example\\n   *\\n   * <pre>\\n   * 64;AutoValue class {@code Foo<T>} {\\n   *   abstract T getFoo;\\n   *\\n   *   64;AutoValueBuilder\\n   *   abstract class {@code Builder<T>} {\\n   *     abstract Builder setFooT t;\\n   *     abstract {@code Foo<T>} build;\\n   *   }\\n   * }\\n   * </pre>\\n   *\\n   * We want to be able to check that the parameter type of {@code setFoo} is the same as the return\\n   * type of {@code getFoo} But in fact it isnt because the {@code T} of {@code Foo<T>} is not\\n   * the same as the {@code T} of {@code FooBuilder<T>} So we create a parallel {@code Foo<T>}\\n   * where the {@code T} <i>is</i> the one from {@code FooBuilder<T>} That way the types do\\n   * correspond This method then returns the return types of the given methods as they appear in\\n   * that parallel class meaning the type given for {@code getFoo} is the {@code T} of {@code\\n   * FooBuilder<T>}\\n   *\\n   * We do the rewrite this way around applying the type parameter from {@code FooBuilder} to\\n   * {@code Foo} because if we hit one of the historical Eclipse bugs with {@link TypesasMemberOf}\\n   * then {@link EclipseHackmethodReturnType} can use fallback logic which only works for methods\\n   * with no arguments\\n   *\\n   * @param methods the methods whose return types are to be rewritten\\n   * @param sourceType the class containing those methods {@code Foo} in the example\\n   * @param targetType the class to translate the methods into {@code FooBuilder<T>} in the\\n   *     example\\n   */   // What were doing is only valid if the type parameters are the same The check here even\\n  // requires the names to be the same The logic would still work without that but we impose\\n  // that requirement elsewhere and it means we can check in this simple way\\n*/\",\n          \"/* // Publish in all the existing single item streams\\n  // This could be improved publishing only in the items that changed Maybe use DiffUtils\\n*/\",\n          \"/*\\n     * Call this to try to give focus to a specific view or to one of its\\n     * descendants\\n     *\\n     * A view will not actually take focus if it is not focusable {@link isFocusable} returns\\n     * false or if it is focusable and it is not focusable in touch mode\\n     * {@link isFocusableInTouchMode} while the device is in touch mode\\n     *\\n     * See also {@link focusSearchint} which is what you call to say that you\\n     * have focus and you want your parent to look for the next one\\n     *\\n     * This is equivalent to calling {@link requestFocusint Rect} with arguments\\n     * {@link FOCUS_DOWN} and <code>null</code>\\n     *\\n     * @return Whether this view or one of its descendants actually took focus\\n     */\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focal_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 414,\n        \"samples\": [\n          \"b'/**\\\\n     * @return {@link SelectorFunction} which selects some size of wide aspect ratio (16:9).\\\\n     */'public static SelectorFunction<Collection<Size>, Size> wideRatio(SelectorFunction<Collection<Size>, Size> selector) {        return aspectRatio(16f / 9f, selector);    }\",\n          \"b'/**\\\\n     * Builds a {@link CaptureRequest} based on the builder parameters.\\\\n     *\\\\n     * @return The capture request.\\\\n     * @throws CameraAccessException If the camera device has been disconnected.\\\\n     */'CaptureRequest build() throws CameraAccessException {        validate();        return Request.create(this);    }\",\n          \"b'/**\\\\n     * @return {@code true} if selected lens position is available. {@code false} if it is not\\\\n     * available.\\\\n     */'public boolean isAvailable() {        return selectedLensPosition() != null;    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1010,\n        \"samples\": [\n          \"@Test    public void _26_TestSelectFilteredSingleColumnSpecifiedStatic()        throws ETSdkException    {        ETResponse<ETDataExtensionRow> response = ETDataExtension.select(client,                                                                         \\\"key=test1\\\",                                                                         \\\"LastName=Flintstone\\\",                                                                         \\\"LastName\\\");        testSelectFilteredSingleColumnSpecified(response);    }\",\n          \"@Test    public void testRandomGraphsS6() throws UnsupportedEncodingException, ExportException, ImportException {        GnpRandomGraphGenerator<Integer, DefaultEdge> gnp=new GnpRandomGraphGenerator<>(40, .55, 0, true);        for(int i=0; i<20; i++){            Graph<Integer, DefaultEdge> orig=new Pseudograph<>(DefaultEdge.class);            gnp.generateGraph(orig, new IntegerVertexFactory(), null);            String res = exportGraph(orig, Graph6Sparse6Exporter.Format.SPARSE6);            Graph<Integer, DefaultEdge> g = importGraph(res);            this.compare(orig, g);        }    }\",\n          \"@Test    public void testToString_whenPathString() {        String pathString = \\\"/bar/baz\\\";        Path p = new GlusterPath(mockFileSystem, pathString);        String filesystemString = \\\"gluster://127.0.2.1:foo\\\";        doReturn(filesystemString).when(mockFileSystem).toString();        assertEquals(pathString, p.toString());    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[8, 2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9Ui1GDfI85O",
        "outputId": "744e1d8d-af46-452e-b406-b86bf3edc27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@Test    public void testSelectOneTaskWithFiveSubmissionCapacityWhenOneAvailableReadyTasks()            throws Exception, GetCountsSlotsException {        Catalog imageStore = mock(Catalog.class);        Arrebol arrebol = mock(Arrebol.class);        Scheduler scheduler = createDefaultScheduler(new DefaultRoundRobin(), arrebol, imageStore);        List<SapsImage> readyTasks = new LinkedList<SapsImage>();        List<SapsImage> downloadedTasks = new LinkedList<SapsImage>();        List<SapsImage> createdTasks = new LinkedList<SapsImage>();        SapsImage task01 = new SapsImage(\"1\", \"landsat_8\", \"217066\", new Date(), ImageTaskState.READY,                SapsImage.NONE_ARREBOL_JOB_ID, \"\", 5, \"user1\", \"nop\", \"\", \"nop\", \"\", \"aio\", \"\", new Timestamp(1),                new Timestamp(1), \"\", \"\");        readyTasks.add(task01);        when(imageStore.getTasksByState(readyState)).thenReturn(readyTasks);        when(imageStore.getTasksByState(downloadedState)).thenReturn(downloadedTasks);        when(imageStore.getTasksByState(createdState)).thenReturn(createdTasks);        when(arrebol.getCountSlotsInQueue(\"default\")).thenReturn(5);        List<SapsImage> selectedTasks = scheduler.selectTasks();        List<SapsImage> expectedSelectedTasks = new LinkedList<SapsImage>();        expectedSelectedTasks.add(task01);        Assert.assertEquals(expectedSelectedTasks, selectedTasks);    }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UTrF4KuzrqY"
      },
      "source": [
        "### **3.2. Quitar Registros**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the length of each cell in each column\n",
        "df['num_characters_description'] = df['description'].apply(lambda x: len(x))\n",
        "df['num_characters_focal'] = df['focal_method'].apply(lambda x: len(x))\n",
        "df['num_characters_test'] = df['test_case'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "fngzUDbj1mo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar registros con num_characters_description menores a 50\n",
        "df = df[df['num_characters_description'] > 50]\n",
        "print(df.shape)\n",
        "\n",
        "# Eliminar registros con num_characters_test menores a 120\n",
        "df = df[df['num_characters_test'] > 120]\n",
        "print(df.shape)\n",
        "\n",
        "# Eliminar registros con num_characters_test mayor a 3000\n",
        "df = df[df['num_characters_test'] <= 3000]\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrkTyD7e1tTV",
        "outputId": "c8d0420e-6b50-4728-fc21-00375fd65178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(915, 6)\n",
            "(896, 6)\n",
            "(881, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['description', 'focal_method', 'test_case']]\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T5GAzCTn_2X",
        "outputId": "9164c610-ba36-432f-9af2-1f2d4a560520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         description  \\\n",
              "0  /*\\n     * This function selects tasks followi...   \n",
              "3  /*\\n     * This function selects tasks followi...   \n",
              "\n",
              "                                        focal_method  \\\n",
              "0  b'/**\\n     * This function selects tasks foll...   \n",
              "3  b'/**\\n     * This function selects tasks foll...   \n",
              "\n",
              "                                           test_case  \n",
              "0  @Test    public void testSelectZeroTasksWithZe...  \n",
              "3  @Test    public void testSelectThreeTasksOneOf...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d26b5eda-686f-48f9-8696-09018b6b10e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>focal_method</th>\n",
              "      <th>test_case</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectThreeTasksOneOf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d26b5eda-686f-48f9-8696-09018b6b10e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d26b5eda-686f-48f9-8696-09018b6b10e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d26b5eda-686f-48f9-8696-09018b6b10e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-634ecac2-ca93-43a1-8f8c-31548d865490\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-634ecac2-ca93-43a1-8f8c-31548d865490')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-634ecac2-ca93-43a1-8f8c-31548d865490 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 881,\n  \"fields\": [\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 349,\n        \"samples\": [\n          \"/*\\nt * Clones the SimpleObject\\nt *\\nt * @param simpleObject\\nt * @return cloned SimpleObject\\nt */\",\n          \"/*\\n     * @param selector selects size of the photo in pixels from list of available sizes\\n     */\",\n          \"/*\\n     * Returns the aspect ratio for this size 1 if invalid dimensions\\n     *\\n     * @return The aspect ratio\\n     */\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focal_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 359,\n        \"samples\": [\n          \"b'/**\\\\n     * Set all the files associated as configuration files for this job.\\\\n     *\\\\n     * @param configs The configuration files to set\\\\n     */'public void setConfigs(@Nullable final Set<FileEntity> configs) {        this.configs.clear();        if (configs != null) {            this.configs.addAll(configs);        }    }\",\n          \"b'/**\\\\n     * Checks if the reference is not null.\\\\n     *\\\\n     * @param reference an object reference\\\\n     * @return the non-null reference\\\\n     * @throws NullPointerException if {@code reference} is null\\\\n     */'@NonNull    public static <T> T get(@Nullable final T reference) {        if (reference == null) {            throw new NullPointerException(\\\"Assertion for a nonnull object failed.\\\");        }        return reference;    }\",\n          \"b'/**\\\\n     * Calculate the LCM between <code>a</code> and <code>b</code> treating <code>start</code> as\\\\n     * the root we want to search from.\\\\n     * \\\\n     * @param start the root of subtree\\\\n     * @param a the first vertex\\\\n     * @param b the second vertex\\\\n     * @return the least common ancestor\\\\n     */'public V calculate(V start, V a, V b)    {        List<LcaRequestResponse<V>> list = new LinkedList<>();        list.add(new LcaRequestResponse<>(a, b));        return calculate(start, list).get(0);    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 875,\n        \"samples\": [\n          \"@Test    public void front_Available() throws Exception {        // Given        List<LensPosition> availablePositions = asList(                LensPosition.BACK,                LensPosition.FRONT,                LensPosition.EXTERNAL        );        // When        LensPosition result = LensPositionSelectors                .front()                .select(availablePositions);        // Then        assertEquals(                LensPosition.FRONT,                result        );    }\",\n          \"@Test    public void parseChromeCapabilities() {        ChromeOptions chromeOptions = new ChromeOptions();        String browserName = \\\"googlechromeheadless\\\";        String browserOptions = \\\"{\\\\\\\"args\\\\\\\":[\\\\\\\"start-maximized\\\\\\\"],\\\\\\\"extensions\\\\\\\":[],\\\\\\\"prefs\\\\\\\":{\\\\\\\"intl.accept_languages\\\\\\\":\\\\\\\"de-AT\\\\\\\"}}\\\";        String desiredCapabilitiesString = \\\"{}\\\";        Capabilities cap = bm.createCapabilities(browserName, desiredCapabilitiesString, browserOptions);        assertTrue(cap.asMap().toString().contains(\\\"--start-maximized\\\"));        assertTrue(cap.asMap().toString().contains(\\\"--headless\\\"));    }\",\n          \"@Test    public void testWithNullName() {        assertSame(                request,                injector.getValue(                        request,                        null,                        SlingHttpServletRequest.class,                        firstConstructorParameter.getAnnotatedElement(),                        registry));        assertNull(injector.getValue(                request,                null,                SlingHttpServletRequest.class,                secondConstructorParameter.getAnnotatedElement(),                registry));        assertNull(injector.getValue(request, null, SlingHttpServletRequest.class, annotatedElement, registry));    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PtoWr0Q7bNd",
        "outputId": "f2471e93-6935-41ff-ed4b-e76fb4023576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(881, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3. Convertir a dataset**"
      ],
      "metadata": {
        "id": "0FexkclvqOF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(df16)\n",
        "#dataset = Dataset.from_pandas(df['description', 'focal_method', 'test_case'])\n",
        "print(dataset)\n",
        "print(\"Dataset cargado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYwb1BXBqWU6",
        "outputId": "bdf91e23-144e-432d-881e-e64221c160f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['description', 'focal_method', 'test_case'],\n",
            "    num_rows: 16\n",
            "})\n",
            "Dataset cargado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir el dataset en 80% train y 20% resto\n",
        "#train_dataset = dataset.train_test_split(test_size=0.2)\n",
        "#test_dataset = train_dataset['test'].train_test_split(test_size=0.5)\n",
        "#datasets = {\n",
        "#    'train': train_dataset['train'],\n",
        "#    'test': test_dataset['test'],\n",
        "#    'validation': test_dataset['train']\n",
        "#}\n",
        "#datasets"
      ],
      "metadata": {
        "id": "S_HzqzjlXOWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prueba = dataset.to_pandas()\n",
        "df_prueba.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "80PnTNWZ6voq",
        "outputId": "1d1644de-5265-4cd7-d9d3-d2eb5d9b4cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         description  \\\n",
              "0  /*\\n     * This function selects tasks followi...   \n",
              "1  /*\\n     * This function selects tasks followi...   \n",
              "2  /*\\n     * This function selects tasks followi...   \n",
              "3  /*\\n     * This function selects tasks followi...   \n",
              "4  /*\\n     * This function selects tasks followi...   \n",
              "\n",
              "                                        focal_method  \\\n",
              "0  b'/**\\n     * This function selects tasks foll...   \n",
              "1  b'/**\\n     * This function selects tasks foll...   \n",
              "2  b'/**\\n     * This function selects tasks foll...   \n",
              "3  b'/**\\n     * This function selects tasks foll...   \n",
              "4  b'/**\\n     * This function selects tasks foll...   \n",
              "\n",
              "                                           test_case  __index_level_0__  \n",
              "0  @Test    public void testSelectZeroTasksWithZe...                  0  \n",
              "1  @Test    public void testSelectThreeTasksOneOf...                  3  \n",
              "2  @Test    public void testSelectZeroTasksWithZe...                  4  \n",
              "3  @Test    public void testSelectZeroTasksWithFi...                  5  \n",
              "4  @Test    public void testSelectOneTaskWithFive...                  6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da9c5ae1-c128-4203-a11a-b191e73aa21c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>focal_method</th>\n",
              "      <th>test_case</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectThreeTasksOneOf...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithZe...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectZeroTasksWithFi...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/*\\n     * This function selects tasks followi...</td>\n",
              "      <td>b'/**\\n     * This function selects tasks foll...</td>\n",
              "      <td>@Test    public void testSelectOneTaskWithFive...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da9c5ae1-c128-4203-a11a-b191e73aa21c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da9c5ae1-c128-4203-a11a-b191e73aa21c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da9c5ae1-c128-4203-a11a-b191e73aa21c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5a41f05c-d441-42bf-9960-edc8d40882f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a41f05c-d441-42bf-9960-edc8d40882f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5a41f05c-d441-42bf-9960-edc8d40882f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_prueba",
              "summary": "{\n  \"name\": \"df_prueba\",\n  \"rows\": 881,\n  \"fields\": [\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 349,\n        \"samples\": [\n          \"/*\\nt * Clones the SimpleObject\\nt *\\nt * @param simpleObject\\nt * @return cloned SimpleObject\\nt */\",\n          \"/*\\n     * @param selector selects size of the photo in pixels from list of available sizes\\n     */\",\n          \"/*\\n     * Returns the aspect ratio for this size 1 if invalid dimensions\\n     *\\n     * @return The aspect ratio\\n     */\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focal_method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 359,\n        \"samples\": [\n          \"b'/**\\\\n     * Set all the files associated as configuration files for this job.\\\\n     *\\\\n     * @param configs The configuration files to set\\\\n     */'public void setConfigs(@Nullable final Set<FileEntity> configs) {        this.configs.clear();        if (configs != null) {            this.configs.addAll(configs);        }    }\",\n          \"b'/**\\\\n     * Checks if the reference is not null.\\\\n     *\\\\n     * @param reference an object reference\\\\n     * @return the non-null reference\\\\n     * @throws NullPointerException if {@code reference} is null\\\\n     */'@NonNull    public static <T> T get(@Nullable final T reference) {        if (reference == null) {            throw new NullPointerException(\\\"Assertion for a nonnull object failed.\\\");        }        return reference;    }\",\n          \"b'/**\\\\n     * Calculate the LCM between <code>a</code> and <code>b</code> treating <code>start</code> as\\\\n     * the root we want to search from.\\\\n     * \\\\n     * @param start the root of subtree\\\\n     * @param a the first vertex\\\\n     * @param b the second vertex\\\\n     * @return the least common ancestor\\\\n     */'public V calculate(V start, V a, V b)    {        List<LcaRequestResponse<V>> list = new LinkedList<>();        list.add(new LcaRequestResponse<>(a, b));        return calculate(start, list).get(0);    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 875,\n        \"samples\": [\n          \"@Test    public void front_Available() throws Exception {        // Given        List<LensPosition> availablePositions = asList(                LensPosition.BACK,                LensPosition.FRONT,                LensPosition.EXTERNAL        );        // When        LensPosition result = LensPositionSelectors                .front()                .select(availablePositions);        // Then        assertEquals(                LensPosition.FRONT,                result        );    }\",\n          \"@Test    public void parseChromeCapabilities() {        ChromeOptions chromeOptions = new ChromeOptions();        String browserName = \\\"googlechromeheadless\\\";        String browserOptions = \\\"{\\\\\\\"args\\\\\\\":[\\\\\\\"start-maximized\\\\\\\"],\\\\\\\"extensions\\\\\\\":[],\\\\\\\"prefs\\\\\\\":{\\\\\\\"intl.accept_languages\\\\\\\":\\\\\\\"de-AT\\\\\\\"}}\\\";        String desiredCapabilitiesString = \\\"{}\\\";        Capabilities cap = bm.createCapabilities(browserName, desiredCapabilitiesString, browserOptions);        assertTrue(cap.asMap().toString().contains(\\\"--start-maximized\\\"));        assertTrue(cap.asMap().toString().contains(\\\"--headless\\\"));    }\",\n          \"@Test    public void testWithNullName() {        assertSame(                request,                injector.getValue(                        request,                        null,                        SlingHttpServletRequest.class,                        firstConstructorParameter.getAnnotatedElement(),                        registry));        assertNull(injector.getValue(                request,                null,                SlingHttpServletRequest.class,                secondConstructorParameter.getAnnotatedElement(),                registry));        assertNull(injector.getValue(request, null, SlingHttpServletRequest.class, annotatedElement, registry));    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"__index_level_0__\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 881,\n        \"samples\": [\n          392,\n          293,\n          553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar inferencia"
      ],
      "metadata": {
        "id": "OItxe15b_XT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1  # Selecciona el primer ejemplo del conjunto de prueba\n",
        "\n",
        "# Extrae la descripción del método y el caso de prueba correspondiente\n",
        "description = datasets['test'][index]['description']\n",
        "test_case = datasets['test'][index]['test_case']\n",
        "\n",
        "# Tokeniza la descripción del método\n",
        "inputs = tokenizer(description, return_tensors='pt')\n",
        "\n",
        "# El modelo genera una salida (test case) basada en la descripción\n",
        "output = tokenizer.decode(\n",
        "    model_base.generate(\n",
        "        inputs[\"input_ids\"],  # IDs de los tokens de la entrada\n",
        "        max_new_tokens=256,   # Limita el número de tokens generados\n",
        "    )[0],  # Selecciona la primera secuencia generada\n",
        "    skip_special_tokens=True  # Omite tokens especiales en la salida\n",
        ")\n",
        "\n",
        "# Imprime los resultados\n",
        "print('-' * 80)\n",
        "print(f'Example')\n",
        "print('-' * 80)\n",
        "print(f'INPUT DESCRIPTION:\\n{description}')  # Descripción del método\n",
        "print('-' * 80)\n",
        "print(f'BASELINE HUMAN TEST CASE:\\n{test_case}')  # Caso de prueba humano\n",
        "print('-' * 80)\n",
        "print(f'MODEL GENERATED ZERO SHOT TEST CASE:\\n{output}\\n')  # Caso generado por el modelo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dOm7XSy2_7I",
        "outputId": "89d0750d-93bf-4017-e812-1178914baaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'datasets' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-951b481533ee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extrae la descripción del método y el caso de prueba correspondiente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_case'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_case_example(index):\n",
        "    \"\"\"Genera y muestra un caso de prueba generado por el modelo basado en el índice proporcionado.\"\"\"\n",
        "\n",
        "    # Extrae la descripción y el caso de prueba del conjunto de datos\n",
        "    description = datasets['test'][index]['description']\n",
        "    test_case = datasets['test'][index]['test_case']\n",
        "\n",
        "    # Construye el prompt para el modelo\n",
        "    prompt = (\n",
        "        f\"Generate a test JUnit for the following method description:\\n\\n\"\n",
        "        f\"{description}\\n\\n\"\n",
        "        f\"Test Case JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    # Tokeniza el prompt\n",
        "    inputs = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = inputs.to(model_base.device) #This line moves inputs to GPU\n",
        "\n",
        "    # Genera la salida del modelo\n",
        "    output = tokenizer.decode(\n",
        "        model_base.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=250,  # Límite de tokens generados por el modelo\n",
        "        )[0],\n",
        "        skip_special_tokens=True  # Omitir tokens especiales en la salida\n",
        "    )\n",
        "\n",
        "    # Imprime los resultados\n",
        "    print('-' * 80)\n",
        "    print(f'Example {index + 1}')\n",
        "    print('-' * 80)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(f'BASELINE HUMAN TEST CASE:\\n{test_case}')\n",
        "    print('-' * 80)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')\n",
        "\n",
        "\n",
        "# Número de ejemplos que se desean mostrar\n",
        "num_examples_to_show = 1\n",
        "\n",
        "# Generar y mostrar el número de ejemplos especificados\n",
        "for i in range(num_examples_to_show):\n",
        "    generate_test_case_example(i)"
      ],
      "metadata": {
        "id": "Fa_thnd9xpIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4: Entrenamiento**"
      ],
      "metadata": {
        "id": "h3q7NP95uDsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1. Tokenizacion**"
      ],
      "metadata": {
        "id": "JUp3atKHuk7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_preprocess(examples, tokenizer, max_length=256):\n",
        "    \"\"\"Tokeniza los inputs y los targets, y prepara las entradas y etiquetas para el modelo.\"\"\"\n",
        "    model_inputs = tokenizer(examples['description'], truncation=True, padding='max_length', max_length=max_length)\n",
        "\n",
        "    # Tokenizar los targets utilizando el tokenizer como target_tokenizer\n",
        "    labels = tokenizer(examples['test_case'], truncation=True, padding='max_length', max_length=max_length)\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Función para preparar los conjuntos de datos\n",
        "def prepare_datasets(dataset: Dataset, tokenizer, test_size: float=0.2, validation_size: float=0.5):\n",
        "    \"\"\"Aplica la tokenización y divide el dataset en entrenamiento, prueba y validación.\"\"\"\n",
        "    # Configurar el token de padding como el token de fin de secuencia\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Aplicar preprocesamiento al dataset\n",
        "    tokenized_dataset = dataset.map(lambda x: tokenize_preprocess(x, tokenizer), batched=True)\n",
        "\n",
        "    # Dividir el dataset en 80% train y 20% resto\n",
        "    train_test_split = tokenized_dataset.train_test_split(test_size=test_size)\n",
        "    test_validation_split = train_test_split['test'].train_test_split(test_size=validation_size)\n",
        "\n",
        "    return {\n",
        "        'train': train_test_split['train'],\n",
        "        'test': test_validation_split['test'],\n",
        "        'validation': test_validation_split['train']\n",
        "    }\n",
        "\n",
        "# Uso de las funciones\n",
        "tokenized_datasets = prepare_datasets(dataset, tokenizer2)\n",
        "print(tokenized_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "5ef51e2a17a94c2aa4de96a6944afe43",
            "ca965d46775f42a484e4ad39e16e61ef",
            "c22ed05df8a74aa08440d85ddb72aaab",
            "57956e8077024c8084d5c75c49092ee2",
            "6c0288de93ad46a799c550d6ad0fbe55",
            "e49dea164c974a0a9ac2c0064f38c64b",
            "dbccf7c37aa340a984b809eccfde78ed",
            "003909bdc59d4192b6c4e3f138441ed2",
            "75c2bebc324547f989d041b2e7276589",
            "a39735433fff4df8861a13c52b8899a6",
            "27c553db4b904ad8a8fd3b8d5fcc8ed4"
          ]
        },
        "id": "CqXv74Gz6GPZ",
        "outputId": "df905982-78d2-4b18-f5e6-7519e495a0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ef51e2a17a94c2aa4de96a6944afe43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': Dataset({\n",
            "    features: ['description', 'focal_method', 'test_case', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 12\n",
            "}), 'test': Dataset({\n",
            "    features: ['description', 'focal_method', 'test_case', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 2\n",
            "}), 'validation': Dataset({\n",
            "    features: ['description', 'focal_method', 'test_case', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 2\n",
            "})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Muestra un registro del dataset tokenized_datasets\n",
        "print(tokenized_datasets['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Rz2FNP3g-1",
        "outputId": "03f37d0c-d750-443b-b192-db9c41f8dc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': '/* // Lets try resolve underlying execution Id\\n  // Lets find and cache ExecutionContext for executionId\\n  // Lets inject execution context info into event using event execution process context \\n*/', 'focal_method': \"@Override    public void add(CloudRuntimeEvent<?, ?> element) {        CommandContext commandContext = getCurrentCommandContext();        // Let's try resolve underlying execution Id        String executionId = resolveExecutionId(element);        // Let's find and cache ExecutionContext for executionId        ExecutionContext executionContext = resolveExecutionContext(commandContext, executionId);        // Let's inject execution context info into event using event execution process context         if(executionContext != null) {            ExecutionContextInfoAppender executionContextInfoAppender = createExecutionContextInfoAppender(executionContext);            CloudRuntimeEventImpl<?,?> event = CloudRuntimeEventImpl.class.cast(element);                        element = executionContextInfoAppender.appendExecutionContextInfoTo(event);        }        super.add(element);            }\", 'test_case': '@Test    public void addShouldCreateAnewListAndRegisterItAsAttributeWhenTheAttributeDoesNotExist() {        //given        given(commandContext.getGenericAttribute(MessageProducerCommandContextCloseListener.PROCESS_ENGINE_EVENTS)).willReturn(null);        //when        eventsAggregator.add(event);        //then        verify(commandContext).addAttribute(eq(MessageProducerCommandContextCloseListener.PROCESS_ENGINE_EVENTS), eventsCaptor.capture());        assertThat(eventsCaptor.getValue()).containsExactly(event);    }', '__index_level_0__': 376, 'input_ids': [128000, 1075, 443, 58166, 1456, 9006, 16940, 11572, 5336, 198, 220, 443, 58166, 1505, 323, 6636, 86551, 369, 11572, 769, 198, 220, 443, 58166, 15921, 11572, 2317, 3630, 1139, 1567, 1701, 1567, 11572, 1920, 2317, 720, 1850, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [128000, 18730, 262, 586, 742, 923, 15346, 4110, 32, 943, 861, 3112, 8861, 2181, 2170, 3994, 4599, 791, 3994, 22186, 46635, 368, 314, 286, 443, 43068, 286, 2728, 15494, 2014, 673, 20560, 3994, 30459, 46108, 4153, 2014, 8084, 2811, 30787, 5359, 63277, 62457, 4682, 45953, 5074, 1237, 286, 443, 9493, 286, 4455, 9219, 59231, 1388, 6368, 1237, 286, 443, 3473, 286, 10356, 15494, 2014, 570, 723, 3994, 71009, 30459, 46108, 4153, 2014, 8084, 2811, 30787, 5359, 63277, 62457, 705, 4455, 34, 33757, 61623, 13732, 286, 17412, 51596, 34, 33757, 12165, 6139, 13676, 66457, 6368, 1237, 262, 335, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001, 128001]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "001eHXPJ3sfW",
        "outputId": "9a631ae2-c759-4d6c-8e18-89a97e71d6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': '/*\\n     * This function selects tasks following a strategy for submit in Arrebol\\n     *\\n     * @return selected tasks list\\n     */',\n",
              " 'focal_method': 'b\\'/**\\\\n     * This function selects tasks following a strategy for submit in Arrebol.\\\\n     *\\\\n     * @return selected tasks list\\\\n     */\\'protected List<SapsImage> selectTasks() {        List<SapsImage> selectedTasks = new LinkedList<SapsImage>();        ImageTaskState[] states = {ImageTaskState.READY, ImageTaskState.DOWNLOADED, ImageTaskState.CREATED};        int countUpToTasks = getCountSlotsInArrebol(\"default\");        for (ImageTaskState state : states) {            List<SapsImage> selectedTasksInCurrentState = selectTasks(countUpToTasks, state);            selectedTasks.addAll(selectedTasksInCurrentState);            countUpToTasks -= selectedTasksInCurrentState.size();        }        return selectedTasks;    }',\n",
              " 'test_case': '@Test    public void testSelectZeroTasksWithZeroSubmissionCapacityWhenThereIsNoAvailableTasks()            throws Exception, GetCountsSlotsException {        Catalog imageStore = mock(Catalog.class);        Arrebol arrebol = mock(Arrebol.class);        Scheduler scheduler = createDefaultScheduler(new DefaultRoundRobin(), arrebol, imageStore);        List<SapsImage> readyTasks = new LinkedList<SapsImage>();        List<SapsImage> downloadedTasks = new LinkedList<SapsImage>();        List<SapsImage> createdTasks = new LinkedList<SapsImage>();        when(imageStore.getTasksByState(readyState)).thenReturn(readyTasks);        when(imageStore.getTasksByState(downloadedState)).thenReturn(downloadedTasks);        when(imageStore.getTasksByState(createdState)).thenReturn(createdTasks);        when(arrebol.getCountSlotsInQueue(\"default\")).thenReturn(0);        List<SapsImage> selectedTasks = scheduler.selectTasks();        List<SapsImage> expectedSelectedTasks = new LinkedList<SapsImage>();        Assert.assertEquals(expectedSelectedTasks, selectedTasks);    }',\n",
              " '__index_level_0__': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Función para crear DataLoaders\n",
        "def create_dataladers(tokenized_dataset, batch_size=8):\n",
        "    train_dataloaoder = DataLoader(tokenized_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    validation_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)  # DataLoader para test\n",
        "    return train_dataloader, validation_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "lTflqC669YF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-O5UqWNiV96"
      },
      "source": [
        "### **4.2. Configuración LoRA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_lora(task_type, r, lora_alpha, lora_dropout):\n",
        "    \"\"\"Configura y retorna los ajustes de LoRA.\"\"\"\n",
        "    lora_config = LoraConfig(\n",
        "        task_type=task_type,\n",
        "        inference_mode=False,  # Modo de entrenamiento\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        lora_dropout=lora_dropout\n",
        "    )\n",
        "    return lora_config\n",
        "\n",
        "def apply_lora_to_model(model_base, lora_config):\n",
        "    \"\"\"Aplica LoRA al modelo y lo mueve al dispositivo especificado.\"\"\"\n",
        "    try:\n",
        "        model = get_peft_model(model_base, lora_config)  # Asumiendo que esta función ya está definida\n",
        "        #model = model.to(device)\n",
        "        print(\"Modelo adaptado con LoRA y movido al dispositivo correctamente.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"Error al aplicar LoRA o mover el modelo al dispositivo: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "AULNCLvS0r4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param} %\"\n",
        "    )\n",
        "#print_trainable_parameters(peft_model_llama)"
      ],
      "metadata": {
        "id": "27rpQVJQy3O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J6kFKj8ifyq"
      },
      "source": [
        "### **4.3. Configuración Finetuning PEFT**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MetricsLogger(TrainerCallback):\n",
        "    \"\"\"Callback to log metrics to WandB and prevent duplicate entries.\"\"\"\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs:\n",
        "            # Define qué métricas quieres loguear en WandB\n",
        "            metrics_to_log = ['loss', 'eval_loss', 'eval_accuracy', 'learning_rate', 'step', 'epoch']\n",
        "            # Filtra y loguea solo las métricas definidas\n",
        "            wandb.log({k: v for k, v in logs.items() if k in metrics_to_log}, step=state.global_step)\n",
        "\n",
        "# Función para calcular métricas\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": (predictions == labels).mean()}\n",
        "\n",
        "# Función para guardar y registrar el modelo\n",
        "def save_and_log_model(trainer, model_name, output_dir, current_datetime):\n",
        "    try:\n",
        "        # Guarda únicamente los pesos del modelo en el directorio especificado para su fácil recarga o distribución.\n",
        "        trainer.model.save_pretrained(output_dir)\n",
        "\n",
        "        # Guarda el modelo completo, incluyendo pesos, configuración, y opcionalmente el estado del optimizador y scheduler, ideal para reanudar el entrenamiento.\n",
        "        trainer.save_model(output_dir) #\n",
        "\n",
        "        # Limpiar el nombre del modelo para usarlo en el nombre del artefacto\n",
        "        sanitized_model_name = re.sub(r\"[^a-zA-Z0-9_.-]\", \"_\", model_name)\n",
        "        artifact_name = f\"peft_model_{sanitized_model_name}_{current_datetime}\"\n",
        "\n",
        "        # Crear y registrar el artefacto\n",
        "        model_artifact = wandb.Artifact(name=artifact_name, type=\"model\", description=f\"Fine-tuned PEFT model based on {model_name}\")\n",
        "        model_artifact.add_dir(output_dir)\n",
        "        wandb.log_artifact(model_artifact)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model saving or artifact logging: {e}\")\n",
        "\n",
        "def init_wandb(training_args, project_name, model_name, file_name, current_datetime):\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=f\"Experimento_{model_name}_{file_name}_{current_datetime}\",\n",
        "        config=vars(training_args)\n",
        "    )\n",
        "\n",
        "def train_model(model, training_args, train_dataset, eval_dataset, compute_metrics, MetricsLogger, model_name, output_dir, current_datetime):\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[MetricsLogger()]\n",
        "    )\n",
        "    try:\n",
        "        results = trainer.train()\n",
        "        save_and_log_model(trainer, model_name, output_dir, current_datetime)\n",
        "    except Exception as e:\n",
        "        print(f\"Ha ocurrido un error durante el entrenamiento: {e}\")\n",
        "    #finally:\n",
        "    #    wandb.finish()"
      ],
      "metadata": {
        "id": "iDzLtIsyq1sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            # Probar si hay suficiente memoria en la GPU\n",
        "            torch.cuda.empty_cache()\n",
        "            return torch.device('cuda')\n",
        "        except RuntimeError:\n",
        "            print(\"Memoria de GPU insuficiente, cambiando a CPU.\")\n",
        "            return torch.device('cpu')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_device()\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfYm-CTbF0zv",
        "outputId": "716a9bf7-0f3f-427b-ec6b-d3bc6b147997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = model.to(device)\n",
        "def configure_training():\n",
        "    lima_tz = pytz.timezone('America/Lima')\n",
        "    current_datetime = datetime.datetime.now(lima_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = f\"./results/run_{current_datetime}\"\n",
        "    print(output_dir)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=8,\n",
        "        learning_rate=5e-4,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        eval_strategy=\"steps\",\n",
        "        #save_strategy=\"epoch\",\n",
        "        eval_steps=1,\n",
        "        save_steps=1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=2,\n",
        "        fp16=True,\n",
        "        save_total_limit=1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"loss\",\n",
        "        greater_is_better=False,\n",
        "        #gradient_checkpointing=True,\n",
        "        #optim=\"paged_adamw_8bit\",\n",
        "        dataloader_num_workers=2\n",
        "        #offload_folder=\"./offload\",       # Carpeta para offloading de memoria\n",
        "        #device_map=\"auto\"                 # Uso automático de la GPU\n",
        "        #optim=\"adamw_torch_fused\"\n",
        "    )\n",
        "    return training_args, output_dir, current_datetime"
      ],
      "metadata": {
        "id": "hC1nHroDxQDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.4. Ejecucion**"
      ],
      "metadata": {
        "id": "VG2p4YTL66Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()  # Esto liberará la memoria no utilizada"
      ],
      "metadata": {
        "id": "oSIHm7xpDwyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "# Imprimir memoria de CPU usada\n",
        "print(f\"Memoria CPU: {psutil.virtual_memory().used / (1024 ** 3):.2f} GB\")\n",
        "\n",
        "# Imprimir uso de memoria en GPU\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOTcaUxZHofU",
        "outputId": "a6036682-c355-4a0a-b94b-cbb62dc8685f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria CPU: 3.58 GB\n",
            "Mon Nov  4 06:07:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0              28W /  70W |  11493MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME_WANDB=\"FinetuningTestCases_shop\"\n",
        "LORA_RANK = 8  # Número de matrices de bajo rango (ajusta según tu GPU)\n",
        "LORA_ALPHA = 16  # Factor de escala para LoRA\n",
        "LORA_DROPOUT = 0.05  # Dropout para regularización\n",
        "TASK_TYPE = TaskType.CAUSAL_LM\n",
        "#DEVICE = get_device() # o 'cpu' dependiendo de tu configuración\n",
        "\n",
        "lora_config = configure_lora(task_type=TASK_TYPE, r=LORA_RANK, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT) # Configurar LoRA\n",
        "peft_model_gemma = apply_lora_to_model(model_base2, lora_config) # Aplicar configuración de LoRA al modelo y moverlo al dispositivo\n",
        "print_trainable_parameters(peft_model_gemma) # Imprimir parámetros entrenables"
      ],
      "metadata": {
        "id": "WqsXXoEiJKvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5492502e-7aab-4b2d-f1de-ff506a1a9519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo adaptado con LoRA y movido al dispositivo correctamente.\n",
            "trainable params: 1089536 || all params: 1544803840 || trainable%: 0.07052908413277896 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# START TRAIN\n",
        "if __name__ == \"__main__\":\n",
        "    peft_training_args, output_dir, current_datetime = configure_training()\n",
        "    init_wandb(peft_training_args, PROJECT_NAME_WANDB, MODEL_NAME, FILE_NAME, current_datetime)\n",
        "    # Prepara el modelo y datos para entrenamiento\n",
        "    #accelerator = Accelerator()\n",
        "    #peft_model_llama, train_dataset, eval_dataset = accelerator.prepare(peft_model_llama, tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"])\n",
        "    train_model(peft_model_gemma, peft_training_args, tokenized_datasets[\"train\"],  tokenized_datasets[\"validation\"], compute_metrics, MetricsLogger, MODEL_NAME, output_dir, current_datetime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "7f64dbf6235e4977b38e849cf4929038",
            "8909e544b9ed416bb7880a3b561e9aa3",
            "1c8dde09c2ab441bb1d0c3fd2988fd89",
            "ef6d2a3ec05b4c1e89f875018114e7ca",
            "24573b9015cb477a9649910a496406b1",
            "bf04389009084b51bfe03bfe7877f0da",
            "c1932892ad884c3b8607c99b0d1fb40a",
            "a0dca299f691497fb3c6e96d12316aaf"
          ]
        },
        "id": "JY7mcvH1xZqt",
        "outputId": "40d4202e-e91f-47c1-f0da-9d1e3ef76167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./results/run_20241104_010804\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113281233338056, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f64dbf6235e4977b38e849cf4929038"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241104_060804-vlp4kke9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/vlp4kke9' target=\"_blank\">Experimento_Qwen2.5-1.5B_dataset1k_20241104_010804</a></strong> to <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/vlp4kke9' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/vlp4kke9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ha ocurrido un error durante el entrenamiento: CUDA out of memory. Tried to allocate 76.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 35.06 MiB is free. Process 748491 has 14.71 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 77.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "9a8dccd24fdc421f8cf23bf3f7159803",
            "f291c669e11d41b884f141c0df11ebd1",
            "822a79cba512419898136354d2aaac72",
            "083ef7df19f440908abbb82dbc7f254c",
            "988352c6b720443b950baf1575202afa",
            "f5c1c9876a494829bca5e6d814312e67",
            "3bd5f3174b924535a1e2943e99f012c1",
            "3089a2db8015468fbf11c668a097a0e1"
          ]
        },
        "id": "mqwmtZ2qdMZ7",
        "outputId": "b05f8deb-4b13-46b0-f9c9-ffb189addb13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a8dccd24fdc421f8cf23bf3f7159803"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Experimento_Qwen2.5-1.5B_dataset1k_20241104_010714</strong> at: <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/535dl9oj' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/535dl9oj</a><br/> View project at: <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241104_060715-535dl9oj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Promp tuning**"
      ],
      "metadata": {
        "id": "ZHJUR7JDge5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PromptTuningConfig, get_peft_model, PeftModelForCausalLM\n",
        "# 4. Configurar el Prompt Tuning\n",
        "peft_tuning_config = PromptTuningConfig(\n",
        "    task_type=\"CAUSAL_LM\",  # Para la tarea de generación de lenguaje (Causal LM)\n",
        "    num_virtual_tokens=20,  # Número de tokens entrenables que se añaden al prompt\n",
        "    prompt_tuning_init=\"TEXT\",  # Inicializar los vectores del prompt con texto\n",
        "    prompt_tuning_init_text=\"Generate a JUnit test case for a Java method.\",  # Texto de inicialización\n",
        "    tokenizer_name_or_path=BASE_MODEL_NAME  # Proveer el tokenizer explícitamente\n",
        ")\n",
        "\n",
        "# 5. Aplicar PEFT (Prompt Tuning) al modelo\n",
        "peft_model = get_peft_model(model_base, peft_tuning_config)\n",
        "\n",
        "# 6. Definir los argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# 7. Inicializar el Trainer\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# 8. Entrenar el modelo\n",
        "trainer.train()\n",
        "\n",
        "# 9. Guardar el modelo ajustado\n",
        "#peft_model.save_pretrained(\"./tuned_model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "bS6UM4wZgidg",
        "outputId": "8ab62128-bae4-4eb5-c175-06624cb64f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcjudithrb\u001b[0m (\u001b[33mcjudithrb-utec\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241029_194401-rayac5am</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cjudithrb-utec/huggingface/runs/rayac5am' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/cjudithrb-utec/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cjudithrb-utec/huggingface' target=\"_blank\">https://wandb.ai/cjudithrb-utec/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cjudithrb-utec/huggingface/runs/rayac5am' target=\"_blank\">https://wandb.ai/cjudithrb-utec/huggingface/runs/rayac5am</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:10, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.844883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.839902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.835892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.985200</td>\n",
              "      <td>0.833232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.985200</td>\n",
              "      <td>0.831376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.985200</td>\n",
              "      <td>0.830565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=18, training_loss=0.9785033331976997, metrics={'train_runtime': 13.089, 'train_samples_per_second': 5.501, 'train_steps_per_second': 1.375, 'total_flos': 107810616508416.0, 'train_loss': 0.9785033331976997, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Probar el modelo con nuevas descripciones de métodos\n",
        "prompt_text = \"Generate a JUnit test case for the following method description: 'This method calculates the area of a circle based on the radius provided as input.'\"\n",
        "inputs = tokenizer(prompt_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Move the inputs tensor to the same device as the model\n",
        "inputs = inputs.to(peft_model.device)\n",
        "\n",
        "# The line below was changed. max_new_tokens was set to control the output length instead of relying on the default max_length of the generate function.\n",
        "outputs = peft_model.generate(**inputs, max_new_tokens=128)  # Adjust max_new_tokens as needed\n",
        "print(\"Generated JUnit test case:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEPdYGa5k05K",
        "outputId": "5869e03a-e099-4436-bced-22e1bc195a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated JUnit test case: Generate a JUnit test case for the following method description: 'This method calculates the area of a circle based on the radius provided as input.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:1755: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n",
            "  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_base.training)  # Debería imprimir True si el modelo está en modo de entrenamiento\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Zj_C6xjii3",
        "outputId": "f5a5b6c0-8b27-4e98-ea95-c5d09a5a2d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5: Evaluación**"
      ],
      "metadata": {
        "id": "a3USNc8pe-Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "bleu = evaluate.load(\"bleu\")"
      ],
      "metadata": {
        "id": "1eIczlk6KjuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1. Evaluando con Rouge**"
      ],
      "metadata": {
        "id": "VLNfvV_p8ViI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_device_eval():\n",
        "    \"\"\"Configura y retorna el dispositivo basado en la disponibilidad de CUDA.\"\"\"\n",
        "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def prepare_data(tokenizer, descriptions):\n",
        "    \"\"\"Prepara y tokeniza los prompts para la generación de texto.\"\"\"\n",
        "    prompts = [\n",
        "        f\"Generate a test JUnit for the following method description: {description}\\n\\nTest case JUnit in Java:\\n\"\n",
        "        for description in descriptions\n",
        "    ]\n",
        "    # Asegúrate de que todos los prompts se procesen en un solo batch\n",
        "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    return inputs\n",
        "\n",
        "def generate_text(model, tokenizer, input_ids, attention_mask):\n",
        "    \"\"\"Genera texto usando el modelo proporcionado y decodifica las salidas.\"\"\"\n",
        "    outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
        "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "\n",
        "def create_report(human_cases, model1_cases, model2_cases, model_name):\n",
        "    \"\"\"Crea un DataFrame con los casos de prueba generados y verifica la longitud de las listas.\"\"\"\n",
        "    if len(human_cases) == len(model1_cases) == len(model2_cases):\n",
        "        zipped_summaries = zip(human_cases, model1_cases, model2_cases)\n",
        "        return pd.DataFrame(zipped_summaries, columns=['HUMAN_BASELINE_TEST_CASES', 'BASE_MODEL_TEST_CASES', f'PEFT_{model_name.upper()}_MODEL_TEST_CASES'])\n",
        "    else:\n",
        "        raise ValueError(\"Las listas de casos de prueba no tienen la misma longitud.\")\n",
        "\n",
        "# Usar funciones en el flujo principal del código\n",
        "device = set_device_eval()\n",
        "model_base.to(device)\n",
        "peft_model_llama.to(device)\n",
        "\n",
        "inputs = prepare_data(tokenizer, tokenized_datasets['test'][:2]['description'])\n",
        "input_ids, attention_mask = inputs.input_ids, inputs.attention_mask#.to(device)\n",
        "\n",
        "base_model_test_cases = generate_text(model_base, tokenizer, input_ids, attention_mask)\n",
        "peft_model_test_cases = generate_text(peft_model_llama, tokenizer, input_ids, attention_mask)\n",
        "human_baseline_test_case = tokenized_datasets['test'][:2]['test_case']\n",
        "\n",
        "df_report = create_report(human_baseline_test_case, base_model_test_cases, peft_model_test_cases, MODEL_NAME)\n",
        "df_report"
      ],
      "metadata": {
        "id": "TMGzz8waB0Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos si CUDA (GPU) está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "descriptions = tokenized_datasets['test'][0:10]['description']\n",
        "human_baseline_test_case = tokenized_datasets['test'][0:10]['test_case']\n",
        "\n",
        "base_model_test_cases = []\n",
        "peft_model_test_cases = []\n",
        "\n",
        "for _, description in enumerate(descriptions):\n",
        "    prompt = (\n",
        "        f\"Generate a test JUnit for the following method description: \"\n",
        "        f\"{description}\\n\\n\"\n",
        "        f\"JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    # Tokenizamos y creamos la attention_mask, moviendo los tensores al dispositivo adecuado (CPU o GPU)\n",
        "    inputs = tokenizer2(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    # Movemos el modelo base al mismo dispositivo que los tensores\n",
        "    #model_base.to(device)\n",
        "    base_model_outputs = model_base2.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Se pasa la atención aquí\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer2.eos_token_id  # Usamos eos_token_id como pad_token_id\n",
        "    )\n",
        "    base_model_text_output = tokenizer2.decode(base_model_outputs[0], skip_special_tokens=True)\n",
        "    base_model_test_cases.append(base_model_text_output)\n",
        "\n",
        "    # Movemos también el peft_model al mismo dispositivo\n",
        "    peft_model_gemma.to(device)\n",
        "    peft_model_outputs = peft_model_gemma.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Se pasa la atención aquí\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer2.eos_token_id  # Usamos eos_token_id como pad_token_id\n",
        "    )\n",
        "    peft_model_text_output = tokenizer2.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "    peft_model_test_cases.append(peft_model_text_output)\n",
        "\n",
        "# Verificar que las listas tengan la misma longitud\n",
        "if len(human_baseline_test_case) == len(base_model_test_cases) == len(peft_model_test_cases):\n",
        "    zipped_summaries = list(zip(human_baseline_test_case, base_model_test_cases, peft_model_test_cases))\n",
        "\n",
        "    df_report = pd.DataFrame(zipped_summaries, columns = ['HUMAN_BASELINE_TEST_CASES', 'BASE_MODEL_TEST_CASES', 'PEFT_'+MODEL_NAME.upper()+'_MODEL_TEST_CASES'])\n",
        "    df_report\n",
        "else:\n",
        "    raise ValueError(\"Las listas de casos de prueba no tienen la misma longitud.\")"
      ],
      "metadata": {
        "id": "bgs4fklcT9lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, description in enumerate(descriptions):\n",
        "    # Crear prompts distintos para cada modelo\n",
        "    prompt_base = (\n",
        "        f\"[Base Model] Generate a test JUnit for the following method description: \"\n",
        "        f\"{description}\\n\\n\"\n",
        "        f\"JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    prompt_peft = (\n",
        "        f\"[PEFT Model] Generate a test JUnit for the following method description: \"\n",
        "        f\"{description}\\n\\n\"\n",
        "        f\"JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    # Generación de input para el modelo base\n",
        "    inputs_base = tokenizer2(prompt_base, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    input_ids_base = inputs_base.input_ids.to(device)\n",
        "    attention_mask_base = inputs_base.attention_mask.to(device)\n",
        "\n",
        "    base_model_outputs = model_base2.generate(\n",
        "        input_ids=input_ids_base,\n",
        "        attention_mask=attention_mask_base,\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer2.eos_token_id\n",
        "    )\n",
        "    base_model_text_output = tokenizer2.decode(base_model_outputs[0], skip_special_tokens=True)\n",
        "    base_model_test_cases.append(base_model_text_output)\n",
        "\n",
        "    # Generación de input para el modelo PEFT\n",
        "    inputs_peft = tokenizer2(prompt_peft, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    input_ids_peft = inputs_peft.input_ids.to(device)\n",
        "    attention_mask_peft = inputs_peft.attention_mask.to(device)\n",
        "\n",
        "    peft_model_outputs = peft_model_gemma.generate(\n",
        "        input_ids=input_ids_peft,\n",
        "        attention_mask=attention_mask_peft,\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer2.eos_token_id\n",
        "    )\n",
        "    peft_model_text_output = tokenizer2.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "    peft_model_test_cases.append(peft_model_text_output)\n",
        "\n",
        "# Verificar que las listas tengan la misma longitud\n",
        "if len(human_baseline_test_case) == len(base_model_test_cases) == len(peft_model_test_cases):\n",
        "    zipped_summaries = list(zip(human_baseline_test_case, base_model_test_cases, peft_model_test_cases))\n",
        "\n",
        "    df_report = pd.DataFrame(zipped_summaries, columns = ['HUMAN_BASELINE_TEST_CASES', 'BASE_MODEL_TEST_CASES', 'PEFT_'+MODEL_NAME.upper()+'_MODEL_TEST_CASES'])\n",
        "    df_report\n",
        "else:\n",
        "    raise ValueError(\"Las listas de casos de prueba no tienen la misma longitud.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "NoFncvbK0_wE",
        "outputId": "17f8f4bb-9eeb-4113-f3ab-c0384a027230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Las listas de casos de prueba no tienen la misma longitud.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-e8b1d9f7be30>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdf_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Las listas de casos de prueba no tienen la misma longitud.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: Las listas de casos de prueba no tienen la misma longitud."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_report"
      ],
      "metadata": {
        "id": "ujFF9qSAUWmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_report.iloc[1,1])"
      ],
      "metadata": {
        "id": "BrmUtFJom6Wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fbd237-a762-439a-a4e0-18a36583f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate a test JUnit for the following method description: This function finds the modulus of two integers and returns the remainder. * @return the modulus of the input integers\n",
            "\n",
            "JUnit in Java:\n",
            "```java\n",
            "import org.junit.Test;\n",
            "\n",
            "public class ModulusTest {\n",
            "\n",
            "    @Test\n",
            "    public void testModulus() {\n",
            "        int a = 10;\n",
            "        int b = 3;\n",
            "        int expected = 1;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithZero() {\n",
            "        int a = 10;\n",
            "        int b = 0;\n",
            "        int expected = 0;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithNegativeNumbers() {\n",
            "        int a = -10;\n",
            "        int b = 3;\n",
            "        int expected = -1;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithNegativeNumbersAndZero() {\n",
            "        int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_report.iloc[1,2])"
      ],
      "metadata": {
        "id": "jxX4e44gUaso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fe8d50-1364-45e3-c240-cc246b5d182a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate a test JUnit for the following method description: This function finds the modulus of two integers and returns the remainder. * @return the modulus of the input integers\n",
            "\n",
            "JUnit in Java:\n",
            "```java\n",
            "import org.junit.Test;\n",
            "\n",
            "public class ModulusTest {\n",
            "\n",
            "    @Test\n",
            "    public void testModulus() {\n",
            "        int a = 10;\n",
            "        int b = 3;\n",
            "        int expected = 1;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithZero() {\n",
            "        int a = 10;\n",
            "        int b = 0;\n",
            "        int expected = 0;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithNegativeNumbers() {\n",
            "        int a = -10;\n",
            "        int b = 3;\n",
            "        int expected = -1;\n",
            "        int actual = Modulus.modulus(a, b);\n",
            "        assert expected == actual;\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testModulusWithNegativeNumbersAndZero() {\n",
            "        int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificamos si CUDA (GPU) está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "descriptions = tokenized_datasets['test'][0:10]['description']\n",
        "human_baseline_test_case = tokenized_datasets['test'][0:10]['test_case']\n",
        "\n",
        "base_model_test_cases = []\n",
        "peft_model_test_cases = []\n",
        "\n",
        "for _, description in enumerate(descriptions):\n",
        "    prompt = (\n",
        "    f\"Generate a test JUnit for the following method description: \"\n",
        "    f\"{description}\\n\\n\"\n",
        "    f\"Test case JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    # Tokenizamos y creamos la attention_mask, moviendo los tensores al dispositivo adecuado (CPU o GPU)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    # Movemos el modelo base al mismo dispositivo que los tensores\n",
        "    #model_base.to(device)\n",
        "    base_model_outputs = model_base.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Se pasa la atención aquí\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer.eos_token_id  # Usamos eos_token_id como pad_token_id\n",
        "    )\n",
        "    base_model_text_output = tokenizer.decode(base_model_outputs[0], skip_special_tokens=True)\n",
        "    base_model_test_cases.append(base_model_text_output)\n",
        "\n",
        "    # Movemos también el peft_model al mismo dispositivo\n",
        "    peft_model_gemma.to(device)\n",
        "    peft_model_outputs = peft_model_gemma.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,  # Se pasa la atención aquí\n",
        "        max_new_tokens=200,\n",
        "        pad_token_id=tokenizer.eos_token_id  # Usamos eos_token_id como pad_token_id\n",
        "    )\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "    peft_model_test_cases.append(peft_model_text_output)\n",
        "\n",
        "# Verificar que las listas tengan la misma longitud\n",
        "if len(human_baseline_test_case) == len(base_model_test_cases) == len(peft_model_test_cases):\n",
        "    zipped_summaries = list(zip(human_baseline_test_case, base_model_test_cases, peft_model_test_cases))\n",
        "\n",
        "    df_report2 = pd.DataFrame(zipped_summaries, columns = ['HUMAN_BASELINE_TEST_CASES', 'BASE_MODEL_TEST_CASES', 'PEFT_'+MODEL_NAME.upper()+'_MODEL_TEST_CASES'])\n",
        "    df_report2\n",
        "else:\n",
        "    raise ValueError(\"Las listas de casos de prueba no tienen la misma longitud.\")"
      ],
      "metadata": {
        "id": "q6I1W7q9Ox3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_report2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "zty57k-B7RTC",
        "outputId": "8769ec17-58df-4580-c44c-839862915b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           HUMAN_BASELINE_TEST_CASES  \\\n",
              "0  @Test  public void missingWildcardBound() {   ...   \n",
              "1  @Test    public void _40_TestSelectFilteredInS...   \n",
              "2  @Test    public void testKeyDownListenerWhenKe...   \n",
              "3  @Test    public void _46_TestSelectFilteredBet...   \n",
              "4  @Test    public void testPairEqualsWithNull() ...   \n",
              "5  @Test    public void testFindBiggest()    {   ...   \n",
              "6  @Test    public void testBinaryTree()    {    ...   \n",
              "7  @Test(expected = IllegalArgumentException.clas...   \n",
              "8  @Test    public void testDecreaseQualityOnlyOn...   \n",
              "9  @Test    public void front_reversePortrait_270...   \n",
              "\n",
              "                               BASE_MODEL_TEST_CASES  \\\n",
              "0  Generate a test JUnit for the following method...   \n",
              "1  Generate a test JUnit for the following method...   \n",
              "2  Generate a test JUnit for the following method...   \n",
              "3  Generate a test JUnit for the following method...   \n",
              "4  Generate a test JUnit for the following method...   \n",
              "5  Generate a test JUnit for the following method...   \n",
              "6  Generate a test JUnit for the following method...   \n",
              "7  Generate a test JUnit for the following method...   \n",
              "8  Generate a test JUnit for the following method...   \n",
              "9  Generate a test JUnit for the following method...   \n",
              "\n",
              "                  PEFT_QWEN2.5-1.5B_MODEL_TEST_CASES  \n",
              "0  Generate a test JUnit for the following method...  \n",
              "1  Generate a test JUnit for the following method...  \n",
              "2  Generate a test JUnit for the following method...  \n",
              "3  Generate a test JUnit for the following method...  \n",
              "4  Generate a test JUnit for the following method...  \n",
              "5  Generate a test JUnit for the following method...  \n",
              "6  Generate a test JUnit for the following method...  \n",
              "7  Generate a test JUnit for the following method...  \n",
              "8  Generate a test JUnit for the following method...  \n",
              "9  Generate a test JUnit for the following method...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81644564-1c2f-4536-aefb-24c7dc6deea4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HUMAN_BASELINE_TEST_CASES</th>\n",
              "      <th>BASE_MODEL_TEST_CASES</th>\n",
              "      <th>PEFT_QWEN2.5-1.5B_MODEL_TEST_CASES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Test  public void missingWildcardBound() {   ...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Test    public void _40_TestSelectFilteredInS...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Test    public void testKeyDownListenerWhenKe...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Test    public void _46_TestSelectFilteredBet...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Test    public void testPairEqualsWithNull() ...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@Test    public void testFindBiggest()    {   ...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@Test    public void testBinaryTree()    {    ...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@Test(expected = IllegalArgumentException.clas...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@Test    public void testDecreaseQualityOnlyOn...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@Test    public void front_reversePortrait_270...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "      <td>Generate a test JUnit for the following method...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81644564-1c2f-4536-aefb-24c7dc6deea4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81644564-1c2f-4536-aefb-24c7dc6deea4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81644564-1c2f-4536-aefb-24c7dc6deea4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a5d2e59-b8fc-4f96-9b56-572b9f2eb2bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a5d2e59-b8fc-4f96-9b56-572b9f2eb2bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a5d2e59-b8fc-4f96-9b56-572b9f2eb2bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4f50bafe-82fb-4ff0-bb5d-eee0d612eefe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_report2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4f50bafe-82fb-4ff0-bb5d-eee0d612eefe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_report2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_report2",
              "summary": "{\n  \"name\": \"df_report2\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"HUMAN_BASELINE_TEST_CASES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"@Test    public void testDecreaseQualityOnlyOnce() {        String url1, url2, url3;        url1 = url2 = url3 = \\\"http://watchlivefree.blogspot.com\\\";        String[] tweetsAsStr = new String[]{            \\\"blap notspamword \\\" + url1,            \\\"blup secondnotspamword \\\" + url2,            \\\"bli secondsomething\\\" + url3};        JUser user = new JUser(\\\"user1\\\");        JTweet tw1 = new JTweet(1L, tweetsAsStr[0], user).setCreatedAt(new Date(1L));        tw1.getUrlEntries().add(new UrlEntry(5, 123, url1).setResolvedTitle(\\\"title1\\\"));        JTweet tw2 = new JTweet(2L, tweetsAsStr[1], user).setCreatedAt(new Date(2L));        tw2.getUrlEntries().add(new UrlEntry(5, 123, url2).setResolvedTitle(\\\"title2\\\"));        JTweet tw3 = new JTweet(3L, tweetsAsStr[2], user).setCreatedAt(new Date(3L));        tw3.getUrlEntries().add(new UrlEntry(5, 123, url3).setResolvedTitle(\\\"title3\\\"));        execute(Arrays.asList(tw1, tw2, tw3));        assertEquals(JTweet.QUAL_MAX, tw1.getQuality());        assertTrue(tw2.getQuality() > JTweet.QUAL_SPAM);        assertTrue(tw3.getQuality() > JTweet.QUAL_SPAM);    }\",\n          \"@Test    public void _40_TestSelectFilteredInStatic1()        throws ETSdkException    {        ETResponse<ETDataExtensionRow> response = ETDataExtension.select(client,                                                                         \\\"key=test1\\\",                                                                         \\\"Age in (34, 35)\\\");        testSelectFilteredIn1(response);    }\",\n          \"@Test    public void testFindBiggest()    {        SimpleGraph<String, DefaultEdge> g = new SimpleGraph<>(DefaultEdge.class);        createGraph(g);        BaseBronKerboschCliqueFinder<String, DefaultEdge> finder = createFinder1(g);        Collection<Set<String>> cliques = new HashSet<>();        finder.maximumIterator().forEachRemaining(cliques::add);        assertEquals(2, cliques.size());        Set<Set<String>> expected = new HashSet<>();        Set<String> set = new HashSet<>();        set.add(V1);        set.add(V2);        set.add(V3);        set.add(V4);        expected.add(set);        set = new HashSet<>();        set.add(V1);        set.add(V2);        set.add(V9);        set.add(V10);        expected.add(set);        // convert result from Collection to Set because we don't want        // order to be significant        Set<Set<String>> actual = new HashSet<>(cliques);        assertEquals(expected, actual);    }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BASE_MODEL_TEST_CASES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Generate a test JUnit for the following method description: /* // HINT do only modify the current tweets quality\\n  // term occurs more than one time on the current tweet\\n  //            twaddQualActionMT;\\n  // now calculate quality via comparing to existing tweets\\n  // prepare indexing and remove terms which do NOT occur in other tweets ie are unimportant\\n  // language detection from twgetLanguages\\n*/\\n\\nTest case JUnit in Java:\\n       \",\n          \"Generate a test JUnit for the following method description: /*\\n     *\\n     * @param client        The ETClient object\\n     * @param dataExtension The data extension \\n     * @param filter        The ETFilter to be used to select rows \\n     * @return              The ETResponse of ETDataExtensionRow \\n     * @throws ETSdkException\\n     */\\n\\nTest case JUnit in Java:\\n\",\n          \"Generate a test JUnit for the following method description: /*\\n     * Calculate the LCM between <code>a</code> and <code>b</code> treating <code>start</code> as\\n     * the root we want to search from\\n     * \\n     * @param start the root of subtree\\n     * @param a the first vertex\\n     * @param b the second vertex\\n     * @return the least common ancestor\\n     */\\n\\nTest case JUnit in Java:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PEFT_QWEN2.5-1.5B_MODEL_TEST_CASES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Generate a test JUnit for the following method description: /* // HINT do only modify the current tweets quality\\n  // term occurs more than one time on the current tweet\\n  //            twaddQualActionMT;\\n  // now calculate quality via comparing to existing tweets\\n  // prepare indexing and remove terms which do NOT occur in other tweets ie are unimportant\\n  // language detection from twgetLanguages\\n*/\\n\\nTest case JUnit in Java:\\n       \",\n          \"Generate a test JUnit for the following method description: /*\\n     *\\n     * @param client        The ETClient object\\n     * @param dataExtension The data extension \\n     * @param filter        The ETFilter to be used to select rows \\n     * @return              The ETResponse of ETDataExtensionRow \\n     * @throws ETSdkException\\n     */\\n\\nTest case JUnit in Java:\\n\",\n          \"Generate a test JUnit for the following method description: /*\\n     * Calculate the LCM between <code>a</code> and <code>b</code> treating <code>start</code> as\\n     * the root we want to search from\\n     * \\n     * @param start the root of subtree\\n     * @param a the first vertex\\n     * @param b the second vertex\\n     * @return the least common ancestor\\n     */\\n\\nTest case JUnit in Java:\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_results_rouge = rouge.compute(\n",
        "    predictions=base_model_test_cases,\n",
        "    references=human_baseline_test_case[0:len(base_model_test_cases)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results_rouge = rouge.compute(\n",
        "    predictions=peft_model_test_cases,\n",
        "    references=human_baseline_test_case[0:len(peft_model_test_cases)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(base_model_results_rouge)\n",
        "\n",
        "print('\\nPEFT MODEL:')\n",
        "print(peft_model_results_rouge)"
      ],
      "metadata": {
        "id": "MPIV1p6x18Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db367c8-5020-457b-edfa-416c9d0ce1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.08107930672268909, 'rouge2': 0.025030525030525032, 'rougeL': 0.08107930672268909, 'rougeLsum': 0.08107930672268909}\n",
            "\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.08107930672268909, 'rouge2': 0.025030525030525032, 'rougeL': 0.08107930672268909, 'rougeLsum': 0.08107930672268909}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.2. Evaluando con Bleu**"
      ],
      "metadata": {
        "id": "SIiL4a_68fAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo base\n",
        "base_model_results_bleu = bleu.compute(\n",
        "    predictions=base_model_test_cases,\n",
        "    references=[[ref] for ref in human_baseline_test_case[0:len(base_model_test_cases)]]\n",
        ")\n",
        "\n",
        "# Evaluar el modelo PEFT\n",
        "peft_model_results_bleu = bleu.compute(\n",
        "    predictions=peft_model_test_cases,\n",
        "    references=[[ref] for ref in human_baseline_test_case[0:len(peft_model_test_cases)]]\n",
        ")\n",
        "\n",
        "# Imprimir resultados\n",
        "print('BASE MODEL BLEU SCORE:')\n",
        "print(base_model_results_bleu)\n",
        "\n",
        "print('\\nPEFT MODEL BLEU SCORE:')\n",
        "print(peft_model_results_bleu)"
      ],
      "metadata": {
        "id": "RjTSAvHw9sya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be14152-4896-4037-a014-e4a123c26b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE MODEL BLEU SCORE:\n",
            "{'bleu': 0.0, 'precisions': [0.10993975903614457, 0.0061162079510703364, 0.0, 0.0], 'brevity_penalty': 0.37741964632733466, 'length_ratio': 0.5064836003051106, 'translation_length': 664, 'reference_length': 1311}\n",
            "\n",
            "PEFT MODEL BLEU SCORE:\n",
            "{'bleu': 0.0, 'precisions': [0.10993975903614457, 0.0061162079510703364, 0.0, 0.0], 'brevity_penalty': 0.37741964632733466, 'length_ratio': 0.5064836003051106, 'translation_length': 664, 'reference_length': 1311}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Registrar los resultados de ROUGE en la sección \"ROUGE\"\n",
        "wandb.log({\n",
        "    \"Test/Base_Model\": base_model_results_rouge,\n",
        "    \"Test/PEFT_Model\": peft_model_results_rouge\n",
        "})\n",
        "\n",
        "# Registrar los resultados de BLEU en la sección \"BLEU\"\n",
        "wandb.log({\n",
        "    \"Test/Base_Model_BLEU\": base_model_results_bleu['bleu'],  # Accediendo al score directamente\n",
        "    \"Test/PEFT_Model_BLEU\": peft_model_results_bleu['bleu']\n",
        "})\n",
        "\n",
        "# Finalizar sesión de WandB\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "GkciggICIEum",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "d760d54b50414907b219d9b6cd42a0a0",
            "590f5bb9de7847a3adb78fb17d68ace6",
            "d08ac98b1b6d448a918066a12a57ed70",
            "aee50054be46474c8fb9f5cd91244c40",
            "3779c15d55844dfc8a57afe65a2c99b2",
            "bdff7887011b42fca8391c87e6327460",
            "0d04e3b2ab6541ff8116664703d52f69",
            "87b5223f516a4e0fa7cf19afc6ab374b"
          ]
        },
        "outputId": "3f8517f5-ff76-4996-f7be-337e9410187c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='8.502 MB of 8.502 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d760d54b50414907b219d9b6cd42a0a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test/Base_Model_BLEU</td><td>▁</td></tr><tr><td>Test/PEFT_Model_BLEU</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>eval/accuracy</td><td>▁▆▇████████</td></tr><tr><td>eval/loss</td><td>█▃▂▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▂▁▇▁█▂▃▅▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▂█▁▇▅▃▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▂█▁▇▅▃█▁</td></tr><tr><td>eval_accuracy</td><td>▁▆▇███████</td></tr><tr><td>eval_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▂▂▁▁▂▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▅▄▂▂▂▁▂▂▃▃▄▃▇▂█▅</td></tr><tr><td>train/learning_rate</td><td>██▇▇▆▆▅▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▁▁▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test/Base_Model_BLEU</td><td>0</td></tr><tr><td>Test/PEFT_Model_BLEU</td><td>0</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>eval/accuracy</td><td>0.62707</td></tr><tr><td>eval/loss</td><td>3.03614</td></tr><tr><td>eval/runtime</td><td>4.7279</td></tr><tr><td>eval/samples_per_second</td><td>3.596</td></tr><tr><td>eval/steps_per_second</td><td>0.635</td></tr><tr><td>eval_accuracy</td><td>0.6273</td></tr><tr><td>eval_loss</td><td>3.03918</td></tr><tr><td>learning_rate</td><td>0</td></tr><tr><td>loss</td><td>3.2821</td></tr><tr><td>total_flos</td><td>5670072144101376.0</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/global_step</td><td>176</td></tr><tr><td>train/grad_norm</td><td>4.23042</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>3.2821</td></tr><tr><td>train_loss</td><td>4.06727</td></tr><tr><td>train_runtime</td><td>473.6916</td></tr><tr><td>train_samples_per_second</td><td>5.945</td></tr><tr><td>train_steps_per_second</td><td>0.372</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Experimento_Qwen2.5-1.5B_dataset1k_20241104_002922</strong> at: <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/262k8gw0' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop/runs/262k8gw0</a><br/> View project at: <a href='https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop' target=\"_blank\">https://wandb.ai/cjudithrb-utec/FinetuningTestCases_shop</a><br/>Synced 5 W&B file(s), 0 media file(s), 13 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241104_052922-262k8gw0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwqoVjKbnX3z"
      },
      "source": [
        "## **Guardar y cargar modelo en HF**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar Modelo"
      ],
      "metadata": {
        "id": "iaEMizjuOx8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar API\n",
        "api = HfApi()\n",
        "\n",
        "def save_model_locally(model, model_path):\n",
        "    \"\"\"Guarda el modelo localmente.\"\"\"\n",
        "    model.save_pretrained(model_path)\n",
        "    tokenizer.save_pretrained(model_path)\n",
        "    print(f\"Modelo guardado localmente en {model_path}.\")\n",
        "\n",
        "def create_or_get_repo(repo_id, token, private=False):\n",
        "    \"\"\"Crea un repositorio en Hugging Face Hub si no existe.\"\"\"\n",
        "    try:\n",
        "        api.create_repo(repo_id=repo_id, token=token, private=private, exist_ok=True)\n",
        "        print(f\"Repositorio listo: {repo_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al crear o acceder al repositorio: {e}\")\n",
        "\n",
        "def upload_lora_adapters(repo_id, lora_model_path, token):\n",
        "    \"\"\"Sube los adaptadores LoRA al Hugging Face Hub.\"\"\"\n",
        "    api.upload_folder(repo_id=repo_id, folder_path=lora_model_path, token=token)\n",
        "    print(f\"Adaptadores LoRA subidos exitosamente en {repo_id}.\")\n",
        "\n",
        "def save_and_upload_quantized_model(model, model_name, tokenizer, hf_user_name, token, quantization_method=\"q4_k_m\"):\n",
        "    \"\"\"Guarda el modelo en formato GGUF cuantizado y lo sube al Hugging Face Hub.\"\"\"\n",
        "    model_gguf_path = f\"{model_name}-gguf\"\n",
        "    model.save_pretrained_gguf(model_gguf_path, tokenizer, quantization_method=quantization_method)\n",
        "    model.push_to_hub_gguf(\n",
        "        repo_id=f\"{hf_user_name}/{model_gguf_path}\",\n",
        "        tokenizer=tokenizer,\n",
        "        quantization_method=quantization_method,\n",
        "        token=token\n",
        "    )\n",
        "    print(f\"Modelo GGUF cuantizado subido en {hf_user_name}/{model_gguf_path}.\")"
      ],
      "metadata": {
        "id": "73c67u50ohWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraciones generales\n",
        "HF_USERNAME = \"Judiht\"\n",
        "HF_TOKEN = os.getenv(\"HUGGING_FACE_HUB_TOKEN\")  # Accede al token de Hugging Face desde una variable de entorno\n",
        "#FILE_NAME2 = \"testcase_generator_16df\"\n",
        "REPO_LOCAL_NAME = f\"{CLEAN_MODEL_NAME}_{FILE_NAME}_{current_datetime}\"\n",
        "REPO_HF_NAME = f\"{HF_USERNAME}/{REPO_LOCAL_NAME}\"\n",
        "\n",
        "# Verificación del token\n",
        "if HF_TOKEN is None:\n",
        "    raise ValueError(\"El token de Hugging Face no está configurado. Asegúrate de definir HUGGING_FACE_HUB_TOKEN en las variables de entorno.\")\n",
        "\n",
        "# Flujo principal\n",
        "# Guardar el modelo base localmente\n",
        "save_model_locally(peft_model_gemma, REPO_LOCAL_NAME)\n",
        "\n",
        "# Crear el repositorio en Hugging Face Hub\n",
        "create_or_get_repo(REPO_HF_NAME, HF_TOKEN)\n",
        "\n",
        "# Subir los adaptadores LoRA\n",
        "upload_lora_adapters(REPO_HF_NAME, REPO_LOCAL_NAME, HF_TOKEN)\n",
        "\n"
      ],
      "metadata": {
        "id": "nzeHzWcwoyHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bcebe30561c5484e9bcf5198406d65f6",
            "d7926b2fc9f34d28b0d697207374029b",
            "18080bc51c694ed8871ec27fa5900be0",
            "90bb833c872b4718b7f7d9d43f7150da",
            "5d15241772d3438f9151b566b73c7632",
            "baa69e5e139545f798a7cbf054fd280a",
            "958fd712fa7e49019b0f1796b7a399ba",
            "ef3fc6cb23f54ce782532a61b4cad306",
            "c35e09d03865475c8a04088d48b454fb",
            "81e728f5d9cf4acf897aefcd24be9abc",
            "89209a6536484c558c1fd9ea595e49c9"
          ]
        },
        "outputId": "6195a624-a56d-4ca4-d95e-1699d630c586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado localmente en Qwen2_5-1_5B_dataset1k_20241104_002922.\n",
            "Repositorio listo: Judiht/Qwen2_5-1_5B_dataset1k_20241104_002922\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.19M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcebe30561c5484e9bcf5198406d65f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptadores LoRA subidos exitosamente en Judiht/Qwen2_5-1_5B_dataset1k_20241104_002922.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar y subir el modelo cuantizado\n",
        "# Asegúrate de que `peft_model_llama` es el modelo fine-tuneado que quieres cuantizar y subir\n",
        "save_and_upload_quantized_model(peft_model_llama, MODEL_NAME, tokenizer, HF_USERNAME, HF_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10-qimgh5eDA",
        "outputId": "49cd6d5b-7725-4095-ce2e-6e343c8646d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LlamaForCausalLM' object has no attribute 'save_pretrained_gguf'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PeftModelForCausalLM' object has no attribute 'save_pretrained_gguf'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'save_pretrained_gguf'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-42f528ca8b6a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Guardar y subir el modelo cuantizado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Asegúrate de que `peft_model_llama` es el modelo fine-tuneado que quieres cuantizar y subir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_and_upload_quantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeft_model_llama\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHF_USERNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHF_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-5b1d2feca535>\u001b[0m in \u001b[0;36msave_and_upload_quantized_model\u001b[0;34m(model, model_name, tokenizer, hf_user_name, token, quantization_method)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"Guarda el modelo en formato GGUF cuantizado y lo sube al Hugging Face Hub.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel_gguf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_name}-gguf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained_gguf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gguf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     model.push_to_hub_gguf(\n\u001b[1;32m     28\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{hf_user_name}/{model_gguf_path}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base_model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_peft_config_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'save_pretrained_gguf'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PqvcL7ZoRma"
      },
      "source": [
        "**Conclusión**\n",
        "\n",
        "Con los parámetros de entrenamiento proporcionados y considerando tu infraestructura local, el fine-tuning del modelo **LLaMA 3-7B** utilizando solo el 10% de tu dataset debería tomar aproximadamente entre **2.5 y 3 horas**. Esta estimación proporciona un rango razonable de tiempo, aunque te recomiendo monitorear el entrenamiento en tiempo real para ajustar cualquier configuración según sea necesario."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar Modelo"
      ],
      "metadata": {
        "id": "nT13S776NxUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_HF_NAME = \"Judiht/Llama-3_2-3B_dataset1k_20241103_214207\""
      ],
      "metadata": {
        "id": "kJWx69YRPr9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración\n",
        "#device = get_device()\n",
        "config = PeftConfig.from_pretrained(REPO_HF_NAME)\n",
        "\n",
        "# Cargar el modelo base con el device_map configurado automáticamente\n",
        "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_NAME, device_map=\"auto\")\n",
        "optimized_model = PeftModel.from_pretrained(base_model, REPO_HF_NAME)\n",
        "\n",
        "# Cargar el tokenizador y establecer el pad_token para evitar advertencias\n",
        "optokenizer = AutoTokenizer.from_pretrained(REPO_HF_NAME, use_fast=True, clean_up_tokenization_spaces=True)\n",
        "optokenizer.pad_token = optokenizer.eos_token\n",
        "\n",
        "# Verificación\n",
        "print(\"Modelo PEFT optimizado cargado correctamente en el dispositivo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2b245451830946fdb1589d47d37153d0",
            "3927ce62907040e9887b7abf27043a7f",
            "a7c0895556964d6cbc3feeed05f937d7",
            "420c39782be6455093960c6cbbe793ee",
            "9cfbbddea29b48b4819d22a0cc71f9f2",
            "e65edaea7c4643bf859c26d02d5a4e02",
            "c726990ca14e436fbbba1838b8ec7815",
            "7f78d4979fca4912ba3939c68b112d08",
            "240c7ef1d1df415994a98923cb84a5c8",
            "e965b854d35b4e81856c43f1978d841f",
            "ca43a4a24cbb4e86a7e8228245e79e24",
            "2f7045bf4683436598c2ceb0ee9d0ce3",
            "b44baaf8312f4e48bc835d376ace2e62",
            "0f0559dcc9b94120924047b633d5dd11",
            "4516fc45817e45e9ba0f8baf87be988e",
            "d0c82c11da80441fbd209e67f08931ef",
            "262dfd1335ec41c99e9bd8ebe96446c5",
            "0acb3437efbb40b18b4e84f68c38efc3",
            "c3ccecb52c77415481c08514c45ef076",
            "726d599b2224492d9e19cc887a0ee3c3",
            "43d08a853d404cdfab9e5a2ad5dce37c",
            "be2305b20cf248e7937c01b64f9c994d"
          ]
        },
        "id": "PEq3ENB3QtxE",
        "outputId": "e3198612-2dbc-44be-f8fa-685da71284cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b245451830946fdb1589d47d37153d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 3758103552 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/2.19M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f7045bf4683436598c2ceb0ee9d0ce3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2400: UserWarning: for base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1462: UserWarning: Current model requires 2147487744 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'base_model.model.model.model.embed_tokens'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-4b887f9b8131>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Cargar el modelo base con el device_map configurado automáticamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_MODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREPO_HF_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Cargar el tokenizador y establecer el pad_token para evitar advertencias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         model.load_adapter(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mload_adapter\u001b[0;34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                 )\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_offload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapters_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0mdispatch_model_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offload_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffload_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m_update_offload\u001b[0;34m(self, offload_index, adapters_weights)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                         \u001b[0msuffix_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                         \u001b[0mextended_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msuffix_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                         \u001b[0msafe_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextended_prefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTunerLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m                             \u001b[0mfinal_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextended_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".base_layer\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'base_model.model.model.model.embed_tokens'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover el modelo a CUDA\n",
        "base_model = peft_model_gemma.to(device)\n",
        "\n",
        "# Definir el prompt para el test JUnit\n",
        "prompt = \"\"\"Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
        "@Test public void testName() { /*assertEquals(expectedResult, actualResult); assertTrue(someCondition); assertFalse(someCondition); */ }\n",
        "Class: App, Method: calculate\n",
        "Description:     /**\n",
        "     * Returns the number of items (values) in the collection.\n",
        "     *\n",
        "     * @return The item count.\n",
        "     */\"\"\"\n",
        "\n",
        "# Formatear el texto completo para la entrada\n",
        "metodo_prompt = \"\"\"###Description:\n",
        "{}\n",
        "\n",
        "### Test Case in junit java:\n",
        "{}\"\"\"\n",
        "\n",
        "text = metodo_prompt.format(prompt, \"\")\n",
        "\n",
        "# Tokenizar el prompt\n",
        "inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generar texto\n",
        "output = peft_model_gemma.generate(**inputs, max_new_tokens=250)\n",
        "\n",
        "# Decodificar la salida generada\n",
        "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDSza7p2OrC7",
        "outputId": "9942ab4f-f620-413f-80b4-65fd9e84796b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-45521cca2a70>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mover el modelo a CUDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Definir el prompt para el test JUnit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m prompt = \"\"\"Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2903\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 )\n\u001b[0;32m-> 2905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Cannot copy out of meta tensor; no data!\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                     raise NotImplementedError(\n\u001b[0m\u001b[1;32m   1334\u001b[0m                         \u001b[0;34mf\"{e} Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m                         \u001b[0;34mf\"when moving module from meta to a different device.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6: Prompting**"
      ],
      "metadata": {
        "id": "h2hPrGa161sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1. Zero-Shot Prompting**"
      ],
      "metadata": {
        "id": "JQ61TdZW7OS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_case_example(index, model, tokenizer):\n",
        "    \"\"\"Genera y muestra un caso de prueba generado por el modelo basado en el índice proporcionado.\"\"\"\n",
        "\n",
        "    # Extraer datos del conjunto de prueba\n",
        "    sample = datasets['test'][index]\n",
        "    description, test_case = sample['description'], sample['test_case']\n",
        "\n",
        "    # Construir el prompt para el modelo\n",
        "    prompt = (\n",
        "        f\"Generate a test JUnit for the following method description:\\n\\n\"\n",
        "        f\"{description}\\n\\n\"\n",
        "        \"Test Case JUnit in Java:\\n\"\n",
        "    )\n",
        "\n",
        "    # Tokenizar el prompt y mover al dispositivo del modelo\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "    # Generar la salida del modelo\n",
        "    output = model.generate(inputs[\"input_ids\"], max_new_tokens=200)\n",
        "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Mostrar los resultados\n",
        "    print('-' * 80)\n",
        "    print(f'Example {index + 1}')\n",
        "    print('-' * 80)\n",
        "    print(f'INPUT PROMPT:\\n{prompt}')\n",
        "    print(f'BASELINE HUMAN TEST CASE:\\n{test_case}')\n",
        "    print('-' * 80)\n",
        "    print(f'MODEL GENERATION - ZERO SHOT:\\n{decoded_output}\\n')\n",
        "\n",
        "# Número de ejemplos a mostrar\n",
        "num_examples_to_show = 1\n",
        "\n",
        "# Parametrizar el modelo para generar y mostrar los ejemplos\n",
        "for i in range(num_examples_to_show):\n",
        "    generate_test_case_example(i, optimized_model, optokenizer)  # Cambia `model_base` por cualquier modelo que desees probar\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vFPmN8Dc3Kl",
        "outputId": "38ad96d4-bf11-4c1a-d29e-e17a9de3dd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Example 1\n",
            "--------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "Generate a test JUnit for the following method description:\n",
            "\n",
            "This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "\n",
            "Test Case JUnit in Java:\n",
            "\n",
            "BASELINE HUMAN TEST CASE:\n",
            "@Test public void testSubtractPositiveNumbers() { assertEquals(1, subtract(4, 3)); }\n",
            "--------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "Generate a test JUnit for the following method description:\n",
            "\n",
            "This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "\n",
            "Test Case JUnit in Java:\n",
            "```\n",
            "import org.junit.Test;\n",
            "import org.junit.runner.RunWith;\n",
            "import org.junit.runners.JUnit4;\n",
            "import org.junit.Assert;\n",
            "\n",
            "@RunWith(JUnit4.class)\n",
            "public class TestAdder {\n",
            "\n",
            "    @Test\n",
            "    public void testAdder() {\n",
            "        Assert.assertEquals(1, adder(1, 1));\n",
            "    }\n",
            "\n",
            "    private int adder(int a, int b) {\n",
            "        return a + b;\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_case_example(index, description, model, tokenizer, class_name=\"AbstractAnnotation\", method_name=\"addChangeListener\"):\n",
        "    # Construye el prompt para el modelo\n",
        "    prompt = (\n",
        "        f\"Write a JUnit test method for the Java method described below. \"\n",
        "        #\"The test method should have @Test and proper and relevant assert statements, \"\n",
        "       # \"and avoid repetition of assert statements.\\n\\n\"\n",
        "        f\"Class: {class_name}\\n\"\n",
        "        f\"Method: {method_name}\\n\"\n",
        "        f\"Description: {description}\\n\\n\"\n",
        "        \"JUnit in Java:\"\n",
        "    )\n",
        "\n",
        "    # Tokenizar el prompt y moverlo al dispositivo del modelo\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "    # Generar la salida del modelo\n",
        "    output = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=250,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Imprimir el caso de prueba generado\n",
        "    print('=' * 80)\n",
        "    print(f'PRUEBA GENERADA #{index + 1}')\n",
        "    print('=' * 80)\n",
        "    print(f'PROMPT DE ENTRADA:\\n{prompt}')\n",
        "    print('\\nCASO DE PRUEBA GENERADO POR EL MODELO:')\n",
        "    print('-' * 80)\n",
        "    print(decoded_output)\n",
        "    print('=' * 80 + '\\n')\n",
        "\n",
        "# Configuración y ejecución\n",
        "NUM_EXAMPLES = 1\n",
        "DESCRIPTION = \"\"\"/**\n",
        "* Registers an object to receive notification of changes to the\n",
        "* annotation.\n",
        "*\n",
        "* @param listener  the object to register.\n",
        "*\n",
        "* @see #removeChangeListener(AnnotationChangeListener)\n",
        "*/\"\"\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Función principal que ejecuta la generación de casos de prueba.\"\"\"\n",
        "    for i in range(NUM_EXAMPLES):\n",
        "        generate_test_case_example(i, DESCRIPTION, optimized_model, optokenizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3O1UB6Ezkis",
        "outputId": "504b22dd-1451-41b0-efd1-ca7429ffc849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PRUEBA GENERADA #1\n",
            "================================================================================\n",
            "PROMPT DE ENTRADA:\n",
            "Write a JUnit test method for the Java method described below. Class: AbstractAnnotation\n",
            "Method: addChangeListener\n",
            "Description: /**\n",
            "* Registers an object to receive notification of changes to the\n",
            "* annotation.\n",
            "*\n",
            "* @param listener  the object to register.\n",
            "*\n",
            "* @see #removeChangeListener(AnnotationChangeListener)\n",
            "*/\n",
            "\n",
            "JUnit in Java:\n",
            "\n",
            "CASO DE PRUEBA GENERADO:\n",
            "--------------------------------------------------------------------------------\n",
            "Write a JUnit test method for the Java method described below. Class: AbstractAnnotation\n",
            "Method: addChangeListener\n",
            "Description: /**\n",
            "* Registers an object to receive notification of changes to the\n",
            "* annotation.\n",
            "*\n",
            "* @param listener  the object to register.\n",
            "*\n",
            "* @see #removeChangeListener(AnnotationChangeListener)\n",
            "*/\n",
            "\n",
            "JUnit in Java: The Basics\n",
            "JUnit in Java: The Basics\n",
            "JUnit in Java: The Basics\n",
            "JUnit in Java: The Basics\n",
            "JUnit in Java: The Basics\n",
            "JUnit in Java: The Basics\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2. Few-Shot Prompting**"
      ],
      "metadata": {
        "id": "1RwpBBlRBGqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_one_or_few_shot(tokenized_dataset, num_examples, start_index=0):\n",
        "    \"\"\"\n",
        "    Construye un prompt few-shot para generación de casos de prueba JUnit.\n",
        "\n",
        "    Args:\n",
        "        tokenized_dataset (dict): Dataset tokenizado.\n",
        "        num_examples (int): Número de ejemplos a incluir en el prompt.\n",
        "        start_index (int): Índice inicial en el dataset.\n",
        "\n",
        "    Returns:\n",
        "        str: Prompt generado.\n",
        "    \"\"\"\n",
        "    total_examples = len(tokenized_dataset['test'])\n",
        "    num_examples = min(num_examples, total_examples - start_index - 1)\n",
        "\n",
        "    # Construcción del prompt\n",
        "    prompt_lines = [\"Generate a unit test in JUnit for each method description.\\n\\n\"]\n",
        "    for i in range(start_index, start_index + num_examples):\n",
        "        example = tokenized_dataset['test'][i]\n",
        "        prompt_lines.extend([\n",
        "            f\"Description: {example['description']}\\n\",\n",
        "            f\"JUnit Test Case:\\n{example['test_case']}\\n\\n\"\n",
        "        ])\n",
        "\n",
        "    # Agregar el último ejemplo sin caso de prueba\n",
        "    final_example = tokenized_dataset['test'][start_index + num_examples]\n",
        "    prompt_lines.append(f\"Description: {final_example['description']}\\nJUnit Test Case:\\n\")\n",
        "\n",
        "    return ''.join(prompt_lines)\n",
        "\n",
        "def generate_test_case_from_prompt(prompt, model, tokenizer, max_new_tokens=250):\n",
        "    \"\"\"\n",
        "    Genera un caso de prueba JUnit a partir de un prompt dado.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Prompt con el cual el modelo generará el caso de prueba.\n",
        "        model: Modelo de generación de lenguaje.\n",
        "        tokenizer: Tokenizador para preparar la entrada del modelo.\n",
        "        max_new_tokens (int): Número máximo de tokens generados.\n",
        "\n",
        "    Returns:\n",
        "        str: Caso de prueba generado por el modelo.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "    output = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "# Ejemplo de uso\n",
        "prompt = make_prompt_one_or_few_shot(tokenized_datasets, num_examples=2, start_index=0)\n",
        "generated_test_case = generate_test_case_from_prompt(prompt, model_base2, tokenizer2)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"FEW-SHOT PROMPT:\\n{prompt}\\n{'='*80}\")\n",
        "print(f\"MODEL GENERATION:\\n{generated_test_case}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcsShjUQ2D2J",
        "outputId": "81619247-fe2c-4257-d229-efe571e42f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT:\n",
            "Generate a unit test in JUnit for each method description.\n",
            "\n",
            "Description: This function calculates the square of an integer and returns the result. * @return the square of the input integer\n",
            "JUnit Test Case:\n",
            "@Test public void testSquareNegativeNumber() { assertEquals(9, square(-3)); }\n",
            "\n",
            "Description: This function calculates the sum of two integers and returns the result. * @return the sum of the input integers\n",
            "JUnit Test Case:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION:\n",
            "Generate a unit test in JUnit for each method description.\n",
            "\n",
            "Description: This function calculates the square of an integer and returns the result. * @return the square of the input integer\n",
            "JUnit Test Case:\n",
            "@Test public void testSquareNegativeNumber() { assertEquals(9, square(-3)); }\n",
            "\n",
            "Description: This function calculates the sum of two integers and returns the result. * @return the sum of the input integers\n",
            "JUnit Test Case:\n",
            "@Test public void testSumPositiveNumbers() { assertEquals(10, sum(5, 5)); }\n",
            "\n",
            "Description: This function calculates the product of two integers and returns the result. * @return the product of the input integers\n",
            "JUnit Test Case:\n",
            "@Test public void testProductPositiveNumbers() { assertEquals(12, product(4, 3)); }\n",
            "\n",
            "Description: This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "JUnit Test Case:\n",
            "@Test public void testDifferencePositiveNumbers() { assertEquals(2, difference(5, 3)); }\n",
            "\n",
            "Description: This function calculates the quotient of two integers and returns the result. * @return the quotient of the input integers\n",
            "JUnit Test Case:\n",
            "@Test public void testQuotientPositiveNumbers() { assertEquals(2, quotient(6, 3)); }\n",
            "\n",
            "Description: This function calculates the remainder of two integers and returns the result. * @return the remainder of the input integers\n",
            "JUnit Test Case:\n",
            "@Test public void testRemainderPositiveNumbers() { assertEquals(2, remainder(6, 3)); }\n",
            "\n",
            "Description: This function calculates the absolute value of an integer and returns the result. * @return the absolute value of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación de dataset\n",
        "datasets2 = {\n",
        "    'test': [\n",
        "        {'description': 'This method calculates the sum of two integers.', 'test_case': '\"@Test public void testSum() { assertEquals(5, YourClass.sum(2, 3)); }'},\n",
        "        #{'description': 'This method initializes the user session.', 'test_case': '@Test public void testInitSession() { User user = new User(); assertNotNull(YourClass.initSession(user)); }'},\n",
        "        {'description': 'This method sorts an array of integers in ascending order.', 'test_case': '@Test public void testSortArray() { int[] expected = {1, 2, 3}; int[] result = YourClass.sortArray(new int[]{3, 2, 1}); assertArrayEquals(expected, result); }'},\n",
        "        {'description': 'This method processes user authentication requests.'}  # Nuevo caso para que el modelo genere\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "9WcPX6b1ft9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de uso\n",
        "prompt = make_prompt_one_or_few_shot(datasets2, num_examples=3, start_index=0)\n",
        "generated_test_case = generate_test_case_from_prompt(prompt, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar el resultado\n",
        "print(f\"FEW-SHOT PROMPT:\\n{prompt}\\n{'='*80}\")\n",
        "print(f\"MODEL GENERATION:\\n{generated_test_case}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyWcnLMfvjA",
        "outputId": "0c180e0d-6469-47f9-d9a0-8e7ecda089c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT:\n",
            "Generate a unit test in JUnit for each method description.\n",
            "\n",
            "Description: This method calculates the sum of two integers.\n",
            "JUnit Test Case:\n",
            "\"@Test public void testSum() { assertEquals(5, YourClass.sum(2, 3)); }\n",
            "\n",
            "Description: This method sorts an array of integers in ascending order.\n",
            "JUnit Test Case:\n",
            "@Test public void testSortArray() { int[] expected = {1, 2, 3}; int[] result = YourClass.sortArray(new int[]{3, 2, 1}); assertArrayEquals(expected, result); }\n",
            "\n",
            "Description: This method processes user authentication requests.\n",
            "JUnit Test Case:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION:\n",
            "Generate a unit test in JUnit for each method description.\n",
            "\n",
            "Description: This method calculates the sum of two integers.\n",
            "JUnit Test Case:\n",
            "\"@Test public void testSum() { assertEquals(5, YourClass.sum(2, 3)); }\n",
            "\n",
            "Description: This method sorts an array of integers in ascending order.\n",
            "JUnit Test Case:\n",
            "@Test public void testSortArray() { int[] expected = {1, 2, 3}; int[] result = YourClass.sortArray(new int[]{3, 2, 1}); assertArrayEquals(expected, result); }\n",
            "\n",
            "Description: This method processes user authentication requests.\n",
            "JUnit Test Case:\n",
            "@Test public void testAuthenticate() { assertTrue(YourClass.authenticate(\"user\", \"password\")); }\n",
            "\n",
            "Description: This method generates a random number between 0 and 100.\n",
            "JUnit Test Case:\n",
            "@Test public void testGenerateRandomNumber() { int randomNumber = YourClass.generateRandomNumber(); assertTrue(randomNumber >= 0 && randomNumber <= 100); }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. Program of Thoughts (PoT) Prompting**"
      ],
      "metadata": {
        "id": "Nqe3DTe5Id3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_one_or_few_shot_pot(tokenized_dataset, num_examples, start_index=0):\n",
        "    \"\"\"\n",
        "    Genera una lista de prompts de tipo Program of Thoughts para un conjunto de ejemplos del dataset.\n",
        "\n",
        "    Args:\n",
        "        tokenized_dataset: Dataset tokenizado con descripciones y casos de prueba.\n",
        "        num_examples: Número de ejemplos para generar prompts.\n",
        "        start_index: Índice a partir del cual comenzar a extraer ejemplos.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de prompts generados.\n",
        "    \"\"\"\n",
        "    total_examples = len(tokenized_dataset['test'])\n",
        "    num_examples = min(num_examples, total_examples - start_index)  # Ajustar el número de ejemplos\n",
        "\n",
        "    # Construcción de prompts usando listas para concatenación eficiente\n",
        "    prompts = [\n",
        "        (\n",
        "            f\"Genera un test unitario para el método siguiente siguiendo estos pasos:\\n\\n\"\n",
        "            f\"Paso 1: Lee y comprende la descripción del método.\\n\"\n",
        "            f\"Descripción del método:{tokenized_dataset['test'][i]['description']}\\n\"\n",
        "            f\"Paso 2: Identifica el comportamiento esperado del método.\\n\"\n",
        "            f\"Paso 3: Construye una clase de prueba JUnit en Java que verifique este comportamiento.\\n\"\n",
        "            f\"Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Y asegurate de usar @Test\\n\\n\"\n",
        "            \"JUnit en Java:\\n\"\n",
        "        )\n",
        "        for i in range(start_index, start_index + num_examples)\n",
        "    ]\n",
        "    return prompts\n",
        "\n",
        "def generate_test_case(prompts, model, tokenizer, max_new_tokens=200):\n",
        "    \"\"\"\n",
        "    Genera casos de prueba a partir de una lista de prompts usando el modelo y el tokenizador.\n",
        "\n",
        "    Args:\n",
        "        prompts (list): Lista de prompts generados.\n",
        "        model: Modelo de lenguaje para generación de texto.\n",
        "        tokenizer: Tokenizador para preparar la entrada del modelo.\n",
        "        max_new_tokens (int): Número máximo de tokens generados.\n",
        "\n",
        "    Returns:\n",
        "        list: Casos de prueba generados por el modelo.\n",
        "    \"\"\"\n",
        "    outputs = []\n",
        "    for prompt in prompts:\n",
        "        # Tokenizar el prompt y moverlo al dispositivo del modelo\n",
        "        inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "        # Generar el texto con el modelo\n",
        "        output = model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        outputs.append(decoded_output)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "# Ejemplo de uso\n",
        "prompts = make_prompt_one_or_few_shot_pot(tokenized_datasets, num_examples=1)\n",
        "generated_outputs = generate_test_case(prompts, model_base2, tokenizer2)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"PoT PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uu88un44GvD",
        "outputId": "e3dec24d-5c84-4f9c-9385-8eac44569ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoT PROMPT #1:\n",
            "Genera un test unitario para el método siguiente siguiendo estos pasos:\n",
            "\n",
            "Paso 1: Lee y comprende la descripción del método.\n",
            "Descripción del método:This function calculates the square of an integer and returns the result. * @return the square of the input integer\n",
            "Paso 2: Identifica el comportamiento esperado del método.\n",
            "Paso 3: Construye una clase de prueba JUnit en Java que verifique este comportamiento.\n",
            "Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Y asegurate de usar @Test\n",
            "\n",
            "JUnit en Java:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "Genera un test unitario para el método siguiente siguiendo estos pasos:\n",
            "\n",
            "Paso 1: Lee y comprende la descripción del método.\n",
            "Descripción del método:This function calculates the square of an integer and returns the result. * @return the square of the input integer\n",
            "Paso 2: Identifica el comportamiento esperado del método.\n",
            "Paso 3: Construye una clase de prueba JUnit en Java que verifique este comportamiento.\n",
            "Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Y asegurate de usar @Test\n",
            "\n",
            "JUnit en Java:\n",
            "import static org.junit.Assert.*;\n",
            "import org.junit.Test;\n",
            "\n",
            "public class SquareCalculatorTest {\n",
            "\n",
            "    @Test\n",
            "    public void testSquareCalculator() {\n",
            "        int input = 5;\n",
            "        int expected = 25;\n",
            "        int actual = SquareCalculator.square(input);\n",
            "        assertEquals(expected, actual);\n",
            "    }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_one_or_few_shot_pot(tokenized_dataset, class_name, method_name, num_examples=1, start_index=0):\n",
        "    \"\"\"\n",
        "    Genera una lista de prompts de tipo Program of Thoughts para un conjunto de ejemplos del dataset.\n",
        "\n",
        "    Args:\n",
        "        tokenized_dataset: Dataset tokenizado con descripciones y casos de prueba.\n",
        "        class_name: Nombre de la clase que contiene el método.\n",
        "        method_name: Nombre del método para el cual se genera el test.\n",
        "        num_examples: Número de ejemplos para generar prompts.\n",
        "        start_index: Índice a partir del cual comenzar a extraer ejemplos.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de prompts generados.\n",
        "    \"\"\"\n",
        "    total_examples = len(tokenized_dataset['test'])\n",
        "    num_examples = min(num_examples, total_examples - start_index)  # Ajustar el número de ejemplos\n",
        "\n",
        "    # Construcción de prompts usando listas para concatenación eficiente\n",
        "    prompts = [\n",
        "        (\n",
        "            f\"Genera un test unitario para el método siguiente siguiendo estos pasos:\\n\\n\"\n",
        "            f\"Paso 1: Lee y comprende la descripción del siguiente método: \"\n",
        "            f\"{tokenized_dataset['test'][i]['description']}\\n\"\n",
        "            f\"Paso 2: Identifica el comportamiento esperado del método.\\n\"\n",
        "            f\"Paso 3: Construye el codigo de una clase de prueba JUnit en Java que verifique este comportamiento.\\n\"\n",
        "            f\"Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Asegúrate de usar @Test\\n\\n\"\n",
        "            f\"Class: {class_name}\\n\"\n",
        "            f\"Method: {method_name}\\n\"\n",
        "            \"JUnit en Java:\\n\"\n",
        "        )\n",
        "        for i in range(start_index, start_index + num_examples)\n",
        "    ]\n",
        "    return prompts\n",
        "\n",
        "# Configuración de clase y método\n",
        "CLASS_NAME = \"AbstractAnnotation\"\n",
        "METHOD_NAME = \"addChangeListener\"\n",
        "\n",
        "# Ejemplo de uso\n",
        "prompts = make_prompt_one_or_few_shot_pot(datasets, CLASS_NAME, METHOD_NAME, num_examples=1)\n",
        "generated_outputs = generate_test_case(prompts, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"PoT PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEobRPVu7FEW",
        "outputId": "5387a014-b300-4da0-d0d8-5f8807115042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT #1:\n",
            "Genera un test unitario para el método siguiente siguiendo estos pasos:\n",
            "\n",
            "Paso 1: Lee y comprende la descripción del siguiente método: This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "Paso 2: Identifica el comportamiento esperado del método.\n",
            "Paso 3: Construye el codigo de una clase de prueba JUnit en Java que verifique este comportamiento.\n",
            "Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Asegúrate de usar @Test\n",
            "\n",
            "Class: AbstractAnnotation\n",
            "Method: addChangeListener\n",
            "JUnit en Java:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "Genera un test unitario para el método siguiente siguiendo estos pasos:\n",
            "\n",
            "Paso 1: Lee y comprende la descripción del siguiente método: This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "Paso 2: Identifica el comportamiento esperado del método.\n",
            "Paso 3: Construye el codigo de una clase de prueba JUnit en Java que verifique este comportamiento.\n",
            "Paso 4: Incluye declaraciones de aserción relevantes en el método de prueba. Asegúrate de usar @Test\n",
            "\n",
            "Class: AbstractAnnotation\n",
            "Method: addChangeListener\n",
            "JUnit en Java:\n",
            "```java\n",
            "@Test\n",
            "public void testAddChangeListener() {\n",
            "    //Arrange\n",
            "    AbstractAnnotation annotation = new AbstractAnnotation();\n",
            "    AnnotationListener listener = new AnnotationListener();\n",
            "    annotation.addChangeListener(listener);\n",
            "    //Act\n",
            "    annotation.addChangeListener(listener);\n",
            "    //Assert\n",
            "    assertEquals(1, annotation.getChangeListeners().size());\n",
            "}\n",
            "```\n",
            "\n",
            "Class: AbstractAnnotation\n",
            "Method: removeChangeListener\n",
            "JUnit en Java:\n",
            "```java\n",
            "@Test\n",
            "public void testRemoveChangeListener() {\n",
            "    //Arrange\n",
            "    AbstractAnnotation annotation = new AbstractAnnotation();\n",
            "    AnnotationListener listener = new AnnotationListener();\n",
            "    annotation.addChangeListener(listener);\n",
            "    //Act\n",
            "    annotation.removeChangeListener(listener);\n",
            "    //Assert\n",
            "    assertEquals(0, annotation.getChangeListeners().size());\n",
            "}\n",
            "```\n",
            "\n",
            "Class: AbstractAnnotation\n",
            "Method: getChangeListeners\n",
            "JUnit en Java:\n",
            "```java\n",
            "@Test\n",
            "public void testGetChangeListeners() {\n",
            "    //Arrange\n",
            "    AbstractAnnotation annotation = new AbstractAnnotation();\n",
            "    AnnotationListener listener = new Annotation\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.4. Chain-of-Code (CoC) Prompting**"
      ],
      "metadata": {
        "id": "W3TydzDimmNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_one_or_few_shot_coc(tokenized_dataset, num_examples, class_name, method_name, start_index=0):\n",
        "    \"\"\"\n",
        "    Genera una lista de prompts en estilo Chain-of-Code para un conjunto de ejemplos del dataset.\n",
        "\n",
        "    Args:\n",
        "        tokenized_dataset (dict): Dataset tokenizado con descripciones y casos de prueba.\n",
        "        num_examples (int): Número de ejemplos para generar prompts.\n",
        "        start_index (int): Índice a partir del cual comenzar a extraer ejemplos.\n",
        "        class_name (str): Nombre de la clase en la cual se encuentra el método.\n",
        "        method_name (str): Nombre del método para el cual se genera el test.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de prompts generados en estilo Chain-of-Code.\n",
        "    \"\"\"\n",
        "    total_examples = len(tokenized_dataset['test'])\n",
        "    num_examples = min(num_examples, total_examples - start_index)\n",
        "\n",
        "    # Crear prompts en estilo Chain-of-Code\n",
        "    prompts = [\n",
        "        (\n",
        "            f\"// Genera un test unitario para el método descrito a continuación.\\n\"\n",
        "            f\"// Clase: {class_name}\\n\"\n",
        "            f\"// Método: {method_name}\\n\"\n",
        "            f\"// Descripción:\\n// {tokenized_dataset['test'][i]['description']}\\n\\n\"\n",
        "            \"Test Unitario JUnit en Java:\\n\"\n",
        "            \"@Test\\n\"\n",
        "        )\n",
        "        for i in range(start_index, start_index + num_examples)\n",
        "    ]\n",
        "\n",
        "    return prompts\n",
        "\n",
        "CLASS_NAME=\"AbstractAnnotation\"\n",
        "METHOD_NAME=\"addChangeListener\"\n",
        "# Ejemplo de uso\n",
        "prompts = make_prompt_one_or_few_shot_coc(datasets, num_examples=1, class_name=CLASS_NAME, method_name=METHOD_NAME)\n",
        "generated_outputs = generate_test_case(prompts, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"CoC PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp4ttCg4-PTq",
        "outputId": "7db644ea-bb95-4d69-bf9e-995def0b21b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT #1:\n",
            "// Genera un test unitario para el método descrito a continuación.\n",
            "// Clase: AbstractAnnotation\n",
            "// Método: addChangeListener\n",
            "// Descripción:\n",
            "// This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "\n",
            "Test Unitario JUnit en Java:\n",
            "@Test\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "// Genera un test unitario para el método descrito a continuación.\n",
            "// Clase: AbstractAnnotation\n",
            "// Método: addChangeListener\n",
            "// Descripción:\n",
            "// This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "\n",
            "Test Unitario JUnit en Java:\n",
            "@Test\n",
            "public void testAddChangeListener() {\n",
            "    AbstractAnnotation abstractAnnotation = new AbstractAnnotation();\n",
            "    abstractAnnotation.addChangeListener(new AbstractAnnotation.ChangeListener() {\n",
            "        @Override\n",
            "        public void onChange(AbstractAnnotation source) {\n",
            "        }\n",
            "    });\n",
            "    abstractAnnotation.addChangeListener(new AbstractAnnotation.ChangeListener() {\n",
            "        @Override\n",
            "        public void onChange(AbstractAnnotation source) {\n",
            "        }\n",
            "    });\n",
            "    assertNotEquals(0, abstractAnnotation.getChangeListeners().size());\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación de dataset\n",
        "dataset2 = {\n",
        "    'test': [\n",
        "        {'description': '/*** Registers an object to receive notification of changes to the* annotation.** @param listener  the object to register.** @see #removeChangeListener(AnnotationChangeListener)*/', 'test_case': ''}\n",
        "        #{'description': 'This method initializes the user session.', 'test_case': '@Test public void testInitSession() { User user = new User(); assertNotNull(YourClass.initSession(user)); }'},\n",
        "        #{'description': 'This method sorts an array of integers in ascending order.', 'test_case': '@Test public void testSortArray() { int[] expected = {1, 2, 3}; int[] result = YourClass.sortArray(new int[]{3, 2, 1}); assertArrayEquals(expected, result); }'},\n",
        "        #{'description': 'This method processes user authentication requests.'}  # Nuevo caso para que el modelo genere\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "TvO6uKLhnKB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAME=\"ClassName\"\n",
        "METHOD_NAME=\"methodName\"\n",
        "# Ejemplo de uso\n",
        "prompts = make_prompt_one_or_few_shot_coc(datasets2, num_examples=1, class_name=CLASS_NAME, method_name=METHOD_NAME)\n",
        "generated_outputs = generate_test_case(prompts, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"CoC PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_98HA27obPS",
        "outputId": "c985d3ff-7e05-4733-9526-852ae422c558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT #1:\n",
            "// Genera un test unitario para el método descrito a continuación.\n",
            "// Clase: ClassName\n",
            "// Método: methodName\n",
            "// Descripción:\n",
            "// This method calculates the sum of two integers.\n",
            "\n",
            "Test Unitario JUnit en Java:\n",
            "@Test\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "// Genera un test unitario para el método descrito a continuación.\n",
            "// Clase: ClassName\n",
            "// Método: methodName\n",
            "// Descripción:\n",
            "// This method calculates the sum of two integers.\n",
            "\n",
            "Test Unitario JUnit en Java:\n",
            "@Test\n",
            "public void testSumaDeDosInt() {\n",
            "    int a = 10;\n",
            "    int b = 20;\n",
            "    int resultado = 30;\n",
            "    int suma = a + b;\n",
            "    assertEquals(resultado, suma);\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.5. Tree-of-Thoughts (ToT) Prompting**"
      ],
      "metadata": {
        "id": "gRczKDW6orQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt_one_or_few_shot_tot(tokenized_dataset, num_examples, start_index=0):\n",
        "    \"\"\"\n",
        "    Genera una lista de prompts en estilo Tree-of-Thoughts para un conjunto de ejemplos del dataset.\n",
        "\n",
        "    Args:\n",
        "        tokenized_dataset: Dataset tokenizado que contiene descripciones y casos de prueba.\n",
        "        num_examples: Número de ejemplos para generar prompts.\n",
        "        start_index: Índice a partir del cual comenzar a extraer ejemplos.\n",
        "\n",
        "    Returns:\n",
        "        Una lista de prompts generados.\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    total_examples = len(tokenized_dataset['test'])\n",
        "\n",
        "    # Asegura que el número de ejemplos no exceda la longitud del dataset\n",
        "    num_examples = min(num_examples, total_examples - start_index)\n",
        "\n",
        "    for i in range(start_index, start_index + num_examples):\n",
        "        test_example = tokenized_dataset['test'][i]\n",
        "        description = test_example['description']\n",
        "\n",
        "        # Prompt en formato Tree-of-Thoughts\n",
        "        prompt = (\n",
        "            f\"Considera las siguientes opciones para generar un test case JUnit para el siguiente método: \"\n",
        "            f\"{description}\\n\"\n",
        "            f\"Opción 1: Crear un test que verifique el valor de retorno esperado del método.\\n\"\n",
        "            f\"Opción 2: Crear un test que verifique el comportamiento del método ante diferentes entradas.\\n\"\n",
        "            f\"Opción 3: Crear un test que evalúe los efectos secundarios del método (si modifica algún estado).\\n\\n\"\n",
        "            f\"Genera el test case JUnit con las opciones anteriores como guía:\\n\"\n",
        "        )\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    return prompts\n"
      ],
      "metadata": {
        "id": "SAsvyiSiov5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAME=\"AbstractAnnotation\"\n",
        "METHOD_NAME=\"addChangeListener\"\n",
        "# Ejemplo de uso\n",
        "prompts = make_prompt_one_or_few_shot_tot(datasets, num_examples=1)\n",
        "generated_outputs = generate_test_case(prompts, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"ToT PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LezQp4EEA5b4",
        "outputId": "8ba6816b-dbdd-4753-c829-4b3f9d80f6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT PROMPT #1:\n",
            "Considera las siguientes opciones para generar un test case JUnit para el siguiente método: This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "Opción 1: Crear un test que verifique el valor de retorno esperado del método.\n",
            "Opción 2: Crear un test que verifique el comportamiento del método ante diferentes entradas.\n",
            "Opción 3: Crear un test que evalúe los efectos secundarios del método (si modifica algún estado).\n",
            "\n",
            "Genera el test case JUnit con las opciones anteriores como guía:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "Considera las siguientes opciones para generar un test case JUnit para el siguiente método: This function calculates the difference between two integers and returns the result. * @return the difference of the input integers\n",
            "Opción 1: Crear un test que verifique el valor de retorno esperado del método.\n",
            "Opción 2: Crear un test que verifique el comportamiento del método ante diferentes entradas.\n",
            "Opción 3: Crear un test que evalúe los efectos secundarios del método (si modifica algún estado).\n",
            "\n",
            "Genera el test case JUnit con las opciones anteriores como guía:\n",
            "```java\n",
            "public class ExampleTest {\n",
            "    @Test\n",
            "    public void test1() {\n",
            "        // option 1\n",
            "        int result = Example.diff(5, 3);\n",
            "        assertEquals(2, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void test2() {\n",
            "        // option 2\n",
            "        int result = Example.diff(5, 3);\n",
            "        assertEquals(2, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void test3() {\n",
            "        // option 3\n",
            "        int result = Example.diff(5, 3);\n",
            "        assertEquals(2, result);\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = make_prompt_one_or_few_shot_tot(datasets2, num_examples=1)\n",
        "generated_outputs = generate_test_case(prompts, optimized_model, optokenizer)\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, (prompt, output) in enumerate(zip(prompts, generated_outputs), 1):\n",
        "    print(f\"ToT PROMPT #{i}:\\n{prompt}\\n{'='*80}\")\n",
        "    print(f\"MODEL GENERATION #{i}:\\n{output}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6HlYwicspNo",
        "outputId": "f8e9acb2-4b5c-4375-a1a8-6d5730e255c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToT PROMPT #1:\n",
            "Considera las siguientes opciones para generar un test case JUnit para el siguiente método: This method calculates the sum of two integers.\n",
            "Opción 1: Crear un test que verifique el valor de retorno esperado del método.\n",
            "Opción 2: Crear un test que verifique el comportamiento del método ante diferentes entradas.\n",
            "Opción 3: Crear un test que evalúe los efectos secundarios del método (si modifica algún estado).\n",
            "\n",
            "Genera el test case JUnit con las opciones anteriores como guía:\n",
            "\n",
            "================================================================================\n",
            "MODEL GENERATION #1:\n",
            "Considera las siguientes opciones para generar un test case JUnit para el siguiente método: This method calculates the sum of two integers.\n",
            "Opción 1: Crear un test que verifique el valor de retorno esperado del método.\n",
            "Opción 2: Crear un test que verifique el comportamiento del método ante diferentes entradas.\n",
            "Opción 3: Crear un test que evalúe los efectos secundarios del método (si modifica algún estado).\n",
            "\n",
            "Genera el test case JUnit con las opciones anteriores como guía:\n",
            "```java\n",
            "public class MyTest {\n",
            "    @Test\n",
            "    public void testSum() {\n",
            "        // TODO: Implementar el test con la opción 1\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumWithDifferentInputs() {\n",
            "        // TODO: Implementar el test con la opción 2\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSideEffects() {\n",
            "        // TODO: Implementar el test con la opción 3\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPnEjf6nX3x"
      },
      "source": [
        "### PrompT 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i07P2ZTVnX3y",
        "outputId": "aadce91c-d4e9-48f2-ff89-abba6d0f56b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>### Method Description:\n",
            "Create test junits based on the comment about method: /** * Returns an object from the list. * @param item  the item index (zero-based). * @return The object (possibly {@code null}). * @throws IndexOutOfBoundsException if {@code item} is out of bounds.*/\n",
            "\n",
            "### Test Case in junit java:\n",
            "```\n",
            "package com.hackerrank.test;\n",
            "\n",
            "import static org.junit.Assert.assertEquals;\n",
            "\n",
            "import org.junit.Test;\n",
            "\n",
            "public class TestArray {\n",
            "\n",
            "    @Test\n",
            "    public void testGet() {\n",
            "        Array arr = new Array(5);\n",
            "        assertEquals(arr.get(1), 1);\n",
            "    }\n",
            "}\n",
            "```<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
        "# Mover el modelo a CUDA solo si está disponible\n",
        "optimized_model = optimized_model.to(device)\n",
        "\n",
        "# Definir el prompt y la descripción\n",
        "method_description = (\n",
        "    \"Create test junits based on the comment about method: \"\n",
        "    \"/** * Returns an object from the list. * @param item  the item index (zero-based).\"\n",
        "    \" * @return The object (possibly {@code null}). * @throws IndexOutOfBoundsException \"\n",
        "    \"if {@code item} is out of bounds.*/\"\n",
        ")\n",
        "metodo_prompt = f\"### Method Description:\\n{method_description}\\n\\n### Test Case in junit java:\\n\"\n",
        "\n",
        "# Tokenizar el prompt y mover los inputs al dispositivo\n",
        "inputs = optokenizer([metodo_prompt], return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Usar TextStreamer para transmisión en tiempo real de la salida del modelo\n",
        "text_streamer = TextStreamer(optokenizer)\n",
        "_ = optimized_model.generate(**inputs, streamer=text_streamer, max_new_tokens=1024)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
        "\n",
        "model = optimized_model\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "prompt = \"\"\"Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
        "@Test public void testName() { /*assertEquals(expectedResult, actualResult); assertTrue(someCondition); assertFalse(someCondition); */}\n",
        "Class: App, Method: calculate\n",
        "Description:     /**\n",
        "     * Returns the number of items (values) in the collection.\n",
        "     *\n",
        "     * @return The item count.\n",
        "     */\"\"\"\n",
        "metodo_prompt = \"\"\"###Description:\n",
        "{}\n",
        "\n",
        "### Test Case in junit java:\n",
        "{}\"\"\"\n",
        "\n",
        "text = metodo_prompt.format(prompt,\"\")\n",
        "\n",
        "inputs = optokenizer([text], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "text_streamer = TextStreamer(optokenizer)\n",
        "\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 1024)\n",
        "\n",
        "# Generar texto\n",
        "#output = model.generate(**inputs, streamer=text_streamer, max_new_tokens=1024)\n",
        "\n",
        "# Decodificar la salida generada\n",
        "#decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "#print(decoded_output)"
      ],
      "metadata": {
        "id": "A3tXSW2cAB3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b044549-97a3-4af2-fbdf-e1128c7fd0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>###Description:\n",
            "Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
            "@Test public void testName() { /*assertEquals(expectedResult, actualResult); assertTrue(someCondition); assertFalse(someCondition); */}\n",
            "Class: App, Method: calculate\n",
            "Description:     /**\n",
            "     * Returns the number of items (values) in the collection.\n",
            "     *\n",
            "     * @return The item count.\n",
            "     */\n",
            "\n",
            "### Test Case in junit java:\n",
            "<|end_of_text|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
        "@Test public void testName() { /*assertEquals(expectedResult, actualResult); assertTrue(someCondition); assertFalse(someCondition); */}\n",
        "Class: KeyedObjects, Method: getItemCount\n",
        "Description:     /**\n",
        "     * Returns the number of items (values) in the collection.\n",
        "     *\n",
        "     * @return The item count.\n",
        "     */\"\"\"\n",
        "metodo_prompt = \"\"\"###Description:\n",
        "{}\n",
        "\n",
        "### Test Case in junit java:\n",
        "{}\"\"\"\n",
        "\n",
        "text = metodo_prompt.format(prompt,\"\")\n",
        "\n",
        "inputs = optokenizer([text], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "text_streamer = TextStreamer(optokenizer)\n",
        "\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 1024)"
      ],
      "metadata": {
        "id": "V2aIWAf9Fp0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9db898f-1b56-4689-fc70-099c2e30745a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>###Description:\n",
            "Write a JUnit test method for the Java method described below. The test method should have proper and relevant assert statements and avoid repetition of assert statements.\n",
            "@Test public void testName() { /*assertEquals(expectedResult, actualResult); assertTrue(someCondition); assertFalse(someCondition); */}\n",
            "Class: KeyedObjects, Method: getItemCount\n",
            "Description:     /**\n",
            "     * Returns the number of items (values) in the collection.\n",
            "     *\n",
            "     * @return The item count.\n",
            "     */\n",
            "\n",
            "### Test Case in junit java:\n",
            "package com.codegym.task.task03.task0310;\n",
            "import org.junit.Test;\n",
            "public class KeyedObjects {\n",
            "    @Test\n",
            "    public void test() {\n",
            "        KeyedObjects test = new KeyedObjects();\n",
            "        assertEquals(1, test.getItemCount(\"key1\"));\n",
            "        assertEquals(2, test.getItemCount(\"key2\"));\n",
            "        assertEquals(3, test.getItemCount(\"key3\"));\n",
            "        assertEquals(4, test.getItemCount(\"key4\"));\n",
            "    }\n",
            "}\n",
            "<|end_of_text|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBh8haEknX3y"
      },
      "source": [
        "### PrompT 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LJWIcvjnX3y",
        "outputId": "5436afbd-07ba-4342-86a9-698971a6e759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>### Method Description:\n",
            "Create comprehensive JUnit test cases for the following method, considering edge cases and potential errors. The method sums two numbers and returns the result.\n",
            "\n",
            "### Requirements:\n",
            "- Test for typical inputs.\n",
            "- Test for boundary conditions (e.g., maximum and minimum values for integers).\n",
            "- Test for incorrect inputs or unexpected behavior (e.g., null values, non-integer inputs).\n",
            "- Include assertions to check the correctness of the output.\n",
            "\n",
            "### Test Cases Junits in Java:\n",
            "```java\n",
            "    @Test\n",
            "    public void testSum() {\n",
            "        int result = Calculator.sum(1, 2);\n",
            "        assertEquals(3, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditions() {\n",
            "        int result = Calculator.sum(1, 2);\n",
            "        assertEquals(3, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsMax() {\n",
            "        int result = Calculator.sum(Integer.MAX_VALUE, 2);\n",
            "        assertEquals(Integer.MAX_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsMin() {\n",
            "        int result = Calculator.sum(1, Integer.MIN_VALUE);\n",
            "        assertEquals(Integer.MIN_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsIntegerMax() {\n",
            "        int result = Calculator.sum(Integer.MAX_VALUE, Integer.MAX_VALUE);\n",
            "        assertEquals(Integer.MAX_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsIntegerMin() {\n",
            "        int result = Calculator.sum(Integer.MIN_VALUE, Integer.MIN_VALUE);\n",
            "        assertEquals(Integer.MIN_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsIntegerNegative() {\n",
            "        int result = Calculator.sum(Integer.MIN_VALUE, -1);\n",
            "        assertEquals(Integer.MIN_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsIntegerPositive() {\n",
            "        int result = Calculator.sum(1, Integer.MAX_VALUE);\n",
            "        assertEquals(Integer.MAX_VALUE, result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNonInteger() {\n",
            "        int result = Calculator.sum(\"a\", 2);\n",
            "        assertEquals(\"a\", result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNull() {\n",
            "        int result = Calculator.sum(null, 2);\n",
            "        assertNull(result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNullLeft() {\n",
            "        int result = Calculator.sum(2, null);\n",
            "        assertNull(result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNullRight() {\n",
            "        int result = Calculator.sum(null, 2);\n",
            "        assertNull(result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNullBoth() {\n",
            "        int result = Calculator.sum(null, null);\n",
            "        assertNull(result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNonIntegerLeft() {\n",
            "        int result = Calculator.sum(\"a\", 2);\n",
            "        assertEquals(\"a\", result);\n",
            "    }\n",
            "\n",
            "    @Test\n",
            "    public void testSumBoundaryConditionsNonIntegerRight() {\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#model = model.to(\"cuda\")\n",
        "prompt = \"Create comprehensive JUnit test cases for the following method, considering edge cases and potential errors. The method sums two numbers and returns the result.\"\n",
        "\n",
        "metodo_prompt = \"\"\"### Method Description:\n",
        "{}\n",
        "\n",
        "### Requirements:\n",
        "- Test for typical inputs.\n",
        "- Test for boundary conditions (e.g., maximum and minimum values for integers).\n",
        "- Test for incorrect inputs or unexpected behavior (e.g., null values, non-integer inputs).\n",
        "- Include assertions to check the correctness of the output.\n",
        "\n",
        "### Test Cases Junit in Java:\n",
        "{}\"\"\"\n",
        "\"\"\n",
        "\n",
        "text = metodo_prompt.format(prompt, \"\")\n",
        "\n",
        "inputs = optokenizer([text], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "text_streamer = TextStreamer(optokenizer)\n",
        "\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 250)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd0S2wjwnX3z",
        "outputId": "b8d91841-8eee-47e1-cc4a-d40e752beb3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[128000,  32215,   1296,  71827,   3196,    304,    279,   4096,    323,\n",
            "           4068,    922,   1749,     25,   8279,   1403,   5219,    198, 128001]],\n",
            "       device='cuda:0')\n",
            "Texto generado: Generate test junit based in the description and comment about method: Sum two numbers\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada para la inferencia\n",
        "input_text = \"Generate test junit based in the description and comment about method: Sum two numbers\"\n",
        "\n",
        "# Tokenizar el texto de entrada\n",
        "#inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "\n",
        "# Tokenizar el texto de entrada\n",
        "# Remove padding=True as the tokenizer doesn't have a padding token\n",
        "inputs = optokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "\n",
        "# Generar la inferencia\n",
        "outputs = model.generate(**inputs, max_length=200, num_return_sequences=1)\n",
        "\n",
        "# Decodificar la salida generada\n",
        "generated_text = optokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(outputs)\n",
        "print(\"Texto generado:\", generated_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xb7gMjncV9pl",
        "cgC4eOh4U7jV",
        "D4VYyHiHqESe",
        "JuagcAu3BhIK",
        "0FexkclvqOF2",
        "OItxe15b_XT1",
        "_-O5UqWNiV96",
        "ZHJUR7JDge5g",
        "a3USNc8pe-Xs",
        "VLNfvV_p8ViI",
        "SIiL4a_68fAE",
        "CwqoVjKbnX3z",
        "nT13S776NxUF",
        "JQ61TdZW7OS1",
        "yKPnEjf6nX3x",
        "WBh8haEknX3y"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f8a79b24c284390982e79d683fed0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afe5385cb6794fbe82e0df873d938880",
              "IPY_MODEL_b405a63270ca49ae87c956213fa4d9b7",
              "IPY_MODEL_7b9146884f27482d9551ebed28c16ca4"
            ],
            "layout": "IPY_MODEL_af7ee967d2ee487a9943b6c54bdc5561"
          }
        },
        "afe5385cb6794fbe82e0df873d938880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc8974736fb040e28ff15c1467609e23",
            "placeholder": "​",
            "style": "IPY_MODEL_795581b5c9694682af2492fc33440d3f",
            "value": "config.json: 100%"
          }
        },
        "b405a63270ca49ae87c956213fa4d9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e688cbadc4b404b85cbc19c0c8db692",
            "max": 844,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9a84f85386f41558cabaa8da1302b32",
            "value": 844
          }
        },
        "7b9146884f27482d9551ebed28c16ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4925a2aa520d4149a345c8a067bda554",
            "placeholder": "​",
            "style": "IPY_MODEL_70f6b49d096e465d80b9a6adb2c27ab0",
            "value": " 844/844 [00:00&lt;00:00, 32.7kB/s]"
          }
        },
        "af7ee967d2ee487a9943b6c54bdc5561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8974736fb040e28ff15c1467609e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "795581b5c9694682af2492fc33440d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e688cbadc4b404b85cbc19c0c8db692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a84f85386f41558cabaa8da1302b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4925a2aa520d4149a345c8a067bda554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f6b49d096e465d80b9a6adb2c27ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9162697e0bf848ba80bd3dfade0fadea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8fc71bde09847a7a870309e29cc6732",
              "IPY_MODEL_9bd6dbdea24c485e9aafbc140c513b75",
              "IPY_MODEL_5c838d4d32344f1abe79d42bf5c826d7"
            ],
            "layout": "IPY_MODEL_3db2007080e24384812a5c9d0e4ef309"
          }
        },
        "f8fc71bde09847a7a870309e29cc6732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506bf371135e4a36a64b17379440728f",
            "placeholder": "​",
            "style": "IPY_MODEL_6afe4be05f3e4a19a5d949f37da752a4",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "9bd6dbdea24c485e9aafbc140c513b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b7e7fd77454199bc899dde2bcb593a",
            "max": 20919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_289c1ca2bc564f7b809b1bb4ca3a5471",
            "value": 20919
          }
        },
        "5c838d4d32344f1abe79d42bf5c826d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1376dc6a1ceb433082559ba1819be37d",
            "placeholder": "​",
            "style": "IPY_MODEL_608b2c36b38a4ed3981af56dfcfba958",
            "value": " 20.9k/20.9k [00:00&lt;00:00, 1.46MB/s]"
          }
        },
        "3db2007080e24384812a5c9d0e4ef309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506bf371135e4a36a64b17379440728f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6afe4be05f3e4a19a5d949f37da752a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b7e7fd77454199bc899dde2bcb593a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289c1ca2bc564f7b809b1bb4ca3a5471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1376dc6a1ceb433082559ba1819be37d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608b2c36b38a4ed3981af56dfcfba958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8d30bf3acc44a9cb529063deab5189e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471dc584ec8945cdb541cc5e58c2b9db",
              "IPY_MODEL_d096bfc66f7d41ada89da114a300781f",
              "IPY_MODEL_88bb355c83b242aa96c6c11fb229e91f"
            ],
            "layout": "IPY_MODEL_4126f2832516449f87babe0eb2fa01da"
          }
        },
        "471dc584ec8945cdb541cc5e58c2b9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8027ee8e8a546e5853c8cdb0893a3ef",
            "placeholder": "​",
            "style": "IPY_MODEL_286174fa97cc4b50b3a88e3e9d019fe7",
            "value": "Downloading shards: 100%"
          }
        },
        "d096bfc66f7d41ada89da114a300781f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931f5d8eda08404188e2afde2a0a4bb2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5d7e16395ac43ab9236a31d21d0d9a0",
            "value": 2
          }
        },
        "88bb355c83b242aa96c6c11fb229e91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa4155e7bcdb4f68a619c15bfffb542f",
            "placeholder": "​",
            "style": "IPY_MODEL_4c7d6a93c3814d2ba104e0ec50e9ddb9",
            "value": " 2/2 [02:32&lt;00:00, 69.13s/it]"
          }
        },
        "4126f2832516449f87babe0eb2fa01da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8027ee8e8a546e5853c8cdb0893a3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286174fa97cc4b50b3a88e3e9d019fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931f5d8eda08404188e2afde2a0a4bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d7e16395ac43ab9236a31d21d0d9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa4155e7bcdb4f68a619c15bfffb542f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7d6a93c3814d2ba104e0ec50e9ddb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a8c962bebf463ebebd8162b341b94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a2738cf3c8f4b0dae541abb5686b6cf",
              "IPY_MODEL_406fe412fbb1432a82112d8333759e12",
              "IPY_MODEL_d1a6e62adb0746a1a6d539536d77d697"
            ],
            "layout": "IPY_MODEL_c69a61fe528a4bfcb5c3b854dbd910ea"
          }
        },
        "4a2738cf3c8f4b0dae541abb5686b6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac408625cd9f46e5a17d27ca858eec4d",
            "placeholder": "​",
            "style": "IPY_MODEL_4b57743c65a349cba4ed46ad3c661402",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "406fe412fbb1432a82112d8333759e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0a166c8661440e90dd1e1badccfad3",
            "max": 4965799096,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5df55fc6f344f389a4017526b0b239e",
            "value": 4965799096
          }
        },
        "d1a6e62adb0746a1a6d539536d77d697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9206bbd085b648939a9c024e20a8c11c",
            "placeholder": "​",
            "style": "IPY_MODEL_3871e3cefbec4a7083770333a9f4b533",
            "value": " 4.97G/4.97G [01:57&lt;00:00, 42.1MB/s]"
          }
        },
        "c69a61fe528a4bfcb5c3b854dbd910ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac408625cd9f46e5a17d27ca858eec4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b57743c65a349cba4ed46ad3c661402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0a166c8661440e90dd1e1badccfad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5df55fc6f344f389a4017526b0b239e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9206bbd085b648939a9c024e20a8c11c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3871e3cefbec4a7083770333a9f4b533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87455c7143c34b73ad91f6fe6a454ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d136779e9d46fb9338120d4209c741",
              "IPY_MODEL_726ab22e186c469fa7218e331682b0e4",
              "IPY_MODEL_3c705724b2a04e5ea504fdbf59cc2ec4"
            ],
            "layout": "IPY_MODEL_db3b0ef9a885426bbb7e0e8c73302ecd"
          }
        },
        "92d136779e9d46fb9338120d4209c741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6767717eac94f518d936b20a4de8502",
            "placeholder": "​",
            "style": "IPY_MODEL_3a4dbbc95aa44c2f88195bc6b96ba683",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "726ab22e186c469fa7218e331682b0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b8c48b7e89245c0aab431f61c739c84",
            "max": 1459729952,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd2ccefd72c44d8c9b0a2c672455a756",
            "value": 1459729952
          }
        },
        "3c705724b2a04e5ea504fdbf59cc2ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1431824d0764669a5fefd7dc002f483",
            "placeholder": "​",
            "style": "IPY_MODEL_ef09dcce388c45e69ff105ab64ddac9b",
            "value": " 1.46G/1.46G [00:34&lt;00:00, 42.4MB/s]"
          }
        },
        "db3b0ef9a885426bbb7e0e8c73302ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6767717eac94f518d936b20a4de8502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a4dbbc95aa44c2f88195bc6b96ba683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b8c48b7e89245c0aab431f61c739c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2ccefd72c44d8c9b0a2c672455a756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1431824d0764669a5fefd7dc002f483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef09dcce388c45e69ff105ab64ddac9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da02f5884d804b34a99bb75398cfdcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc4cd561f9864c6e956c1883aca2258f",
              "IPY_MODEL_050166e9561741b4bdabf7fec1da8e07",
              "IPY_MODEL_fb1d9a0bdc2e4984b93c726fc6d7c19d"
            ],
            "layout": "IPY_MODEL_5a49df75413f446ab18a0fc5a2a5f890"
          }
        },
        "dc4cd561f9864c6e956c1883aca2258f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8980c9a71a4bd89c2fc2afc607cab1",
            "placeholder": "​",
            "style": "IPY_MODEL_765f25121d7349b4a4c7bc433feacfad",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "050166e9561741b4bdabf7fec1da8e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73dfa40baadb4c05a6558cf43f49c832",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc6dd44637674318b4ba1a53abd364bb",
            "value": 2
          }
        },
        "fb1d9a0bdc2e4984b93c726fc6d7c19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9e95d48cb68463fa194d01e18048f98",
            "placeholder": "​",
            "style": "IPY_MODEL_5c1154b1d6af4fb780d22fb3f4251ab7",
            "value": " 2/2 [00:28&lt;00:00, 12.97s/it]"
          }
        },
        "5a49df75413f446ab18a0fc5a2a5f890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8980c9a71a4bd89c2fc2afc607cab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765f25121d7349b4a4c7bc433feacfad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73dfa40baadb4c05a6558cf43f49c832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6dd44637674318b4ba1a53abd364bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9e95d48cb68463fa194d01e18048f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1154b1d6af4fb780d22fb3f4251ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "866bf815167944d5b9e82cfcf70738f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6f7827e3aed414f8bcb978fca702564",
              "IPY_MODEL_466db3b0159b4c8392094541ce7367b8",
              "IPY_MODEL_5f6b57fca7d04dd8a895243529b42579"
            ],
            "layout": "IPY_MODEL_2883f1ae72154d4b85c0c251650b286f"
          }
        },
        "a6f7827e3aed414f8bcb978fca702564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4c8f010e3f346a99990f5af779c1d5a",
            "placeholder": "​",
            "style": "IPY_MODEL_1b4b6a16f45b4c6699d8e9c5f4614604",
            "value": "generation_config.json: 100%"
          }
        },
        "466db3b0159b4c8392094541ce7367b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d57e893bb24420bbf2dc274cdfe6075",
            "max": 185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_551b527cad3b493aa2a1ed07493aa197",
            "value": 185
          }
        },
        "5f6b57fca7d04dd8a895243529b42579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_654a64d109b6460fab7102805d558d16",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa4140d9e63443f8d3e1ece80972008",
            "value": " 185/185 [00:00&lt;00:00, 8.30kB/s]"
          }
        },
        "2883f1ae72154d4b85c0c251650b286f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c8f010e3f346a99990f5af779c1d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4b6a16f45b4c6699d8e9c5f4614604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d57e893bb24420bbf2dc274cdfe6075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "551b527cad3b493aa2a1ed07493aa197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "654a64d109b6460fab7102805d558d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa4140d9e63443f8d3e1ece80972008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf7afef981d49b68cb0133e8846ec36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5f45e4305144133b73324965ee1f33f",
              "IPY_MODEL_b042240560dc4adf926e31a4cc64a8e2",
              "IPY_MODEL_1911798d527741f882d467ddaf3eb069"
            ],
            "layout": "IPY_MODEL_047ededd5cbc405cbcab294264e3c19f"
          }
        },
        "e5f45e4305144133b73324965ee1f33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb782c5bcf14b93a21202bdbc07d1cb",
            "placeholder": "​",
            "style": "IPY_MODEL_118731b8958745328c16734a9a4a2e63",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b042240560dc4adf926e31a4cc64a8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff24fed795b44588a6df8e0f20b56f1",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8133f21a51a47dbb20436d5c61f7016",
            "value": 50500
          }
        },
        "1911798d527741f882d467ddaf3eb069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbecc94dfa244a3a35382379283fce6",
            "placeholder": "​",
            "style": "IPY_MODEL_7adc595144e54d0eb0bd322adf98250b",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 1.61MB/s]"
          }
        },
        "047ededd5cbc405cbcab294264e3c19f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb782c5bcf14b93a21202bdbc07d1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "118731b8958745328c16734a9a4a2e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ff24fed795b44588a6df8e0f20b56f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8133f21a51a47dbb20436d5c61f7016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfbecc94dfa244a3a35382379283fce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7adc595144e54d0eb0bd322adf98250b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29941c21e2fa4a6ea8a135c476213d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_821dec6ccca043dcba5ecf69e67b80b5",
              "IPY_MODEL_e028c6b5e2ba48efaf6ff7c30850e4c0",
              "IPY_MODEL_2c7f3391e6114109ba533ba3ba004444"
            ],
            "layout": "IPY_MODEL_f7f2135178a34bbfa65b463823c3779c"
          }
        },
        "821dec6ccca043dcba5ecf69e67b80b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e197c9cb56b4043ac15757aa42642cb",
            "placeholder": "​",
            "style": "IPY_MODEL_3153f4c473254fb4adbc713ed0495b2a",
            "value": "tokenizer.json: 100%"
          }
        },
        "e028c6b5e2ba48efaf6ff7c30850e4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aedce3328624c688b5a660401a024c1",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5f5696c995f46ef925f7d501da51d56",
            "value": 9085657
          }
        },
        "2c7f3391e6114109ba533ba3ba004444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95038a08530d4d0e8c84926edafa5dfb",
            "placeholder": "​",
            "style": "IPY_MODEL_e1699a5436bc4961b2d3770fa9e01ce1",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "f7f2135178a34bbfa65b463823c3779c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e197c9cb56b4043ac15757aa42642cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3153f4c473254fb4adbc713ed0495b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aedce3328624c688b5a660401a024c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f5696c995f46ef925f7d501da51d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95038a08530d4d0e8c84926edafa5dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1699a5436bc4961b2d3770fa9e01ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "489f86ca168c421c8313858363af7f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20e87f605f144302b9cbccc8447d5c0a",
              "IPY_MODEL_d3c99db340e5487f9a59b5620e3986d8",
              "IPY_MODEL_62077152b08640c2b6dd655948d3eaf3"
            ],
            "layout": "IPY_MODEL_e1a44be87a6f4f99a7e09f2db4fa9df1"
          }
        },
        "20e87f605f144302b9cbccc8447d5c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_898051fc804547749be8b15214142925",
            "placeholder": "​",
            "style": "IPY_MODEL_da8c920861614255abd61603548033e6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d3c99db340e5487f9a59b5620e3986d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c83764d1f8264739bf55fa568ee05799",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1d9b59bc6f0406690cef95e8f78ed6f",
            "value": 301
          }
        },
        "62077152b08640c2b6dd655948d3eaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803abcdae741487ca2b861848ceebd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_6f5e42ead5b74b1e8e5fbd528efa0136",
            "value": " 301/301 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "e1a44be87a6f4f99a7e09f2db4fa9df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898051fc804547749be8b15214142925": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da8c920861614255abd61603548033e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c83764d1f8264739bf55fa568ee05799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d9b59bc6f0406690cef95e8f78ed6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "803abcdae741487ca2b861848ceebd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5e42ead5b74b1e8e5fbd528efa0136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ef51e2a17a94c2aa4de96a6944afe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca965d46775f42a484e4ad39e16e61ef",
              "IPY_MODEL_c22ed05df8a74aa08440d85ddb72aaab",
              "IPY_MODEL_57956e8077024c8084d5c75c49092ee2"
            ],
            "layout": "IPY_MODEL_6c0288de93ad46a799c550d6ad0fbe55"
          }
        },
        "ca965d46775f42a484e4ad39e16e61ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e49dea164c974a0a9ac2c0064f38c64b",
            "placeholder": "​",
            "style": "IPY_MODEL_dbccf7c37aa340a984b809eccfde78ed",
            "value": "Map: 100%"
          }
        },
        "c22ed05df8a74aa08440d85ddb72aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_003909bdc59d4192b6c4e3f138441ed2",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75c2bebc324547f989d041b2e7276589",
            "value": 16
          }
        },
        "57956e8077024c8084d5c75c49092ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39735433fff4df8861a13c52b8899a6",
            "placeholder": "​",
            "style": "IPY_MODEL_27c553db4b904ad8a8fd3b8d5fcc8ed4",
            "value": " 16/16 [00:00&lt;00:00, 161.78 examples/s]"
          }
        },
        "6c0288de93ad46a799c550d6ad0fbe55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49dea164c974a0a9ac2c0064f38c64b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbccf7c37aa340a984b809eccfde78ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "003909bdc59d4192b6c4e3f138441ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c2bebc324547f989d041b2e7276589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a39735433fff4df8861a13c52b8899a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c553db4b904ad8a8fd3b8d5fcc8ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f64dbf6235e4977b38e849cf4929038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8909e544b9ed416bb7880a3b561e9aa3",
              "IPY_MODEL_1c8dde09c2ab441bb1d0c3fd2988fd89"
            ],
            "layout": "IPY_MODEL_ef6d2a3ec05b4c1e89f875018114e7ca"
          }
        },
        "8909e544b9ed416bb7880a3b561e9aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24573b9015cb477a9649910a496406b1",
            "placeholder": "​",
            "style": "IPY_MODEL_bf04389009084b51bfe03bfe7877f0da",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "1c8dde09c2ab441bb1d0c3fd2988fd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1932892ad884c3b8607c99b0d1fb40a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0dca299f691497fb3c6e96d12316aaf",
            "value": 1
          }
        },
        "ef6d2a3ec05b4c1e89f875018114e7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24573b9015cb477a9649910a496406b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf04389009084b51bfe03bfe7877f0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1932892ad884c3b8607c99b0d1fb40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0dca299f691497fb3c6e96d12316aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a8dccd24fdc421f8cf23bf3f7159803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f291c669e11d41b884f141c0df11ebd1",
              "IPY_MODEL_822a79cba512419898136354d2aaac72"
            ],
            "layout": "IPY_MODEL_083ef7df19f440908abbb82dbc7f254c"
          }
        },
        "f291c669e11d41b884f141c0df11ebd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_988352c6b720443b950baf1575202afa",
            "placeholder": "​",
            "style": "IPY_MODEL_f5c1c9876a494829bca5e6d814312e67",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "822a79cba512419898136354d2aaac72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd5f3174b924535a1e2943e99f012c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3089a2db8015468fbf11c668a097a0e1",
            "value": 1
          }
        },
        "083ef7df19f440908abbb82dbc7f254c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988352c6b720443b950baf1575202afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c1c9876a494829bca5e6d814312e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bd5f3174b924535a1e2943e99f012c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3089a2db8015468fbf11c668a097a0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d760d54b50414907b219d9b6cd42a0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_590f5bb9de7847a3adb78fb17d68ace6",
              "IPY_MODEL_d08ac98b1b6d448a918066a12a57ed70"
            ],
            "layout": "IPY_MODEL_aee50054be46474c8fb9f5cd91244c40"
          }
        },
        "590f5bb9de7847a3adb78fb17d68ace6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3779c15d55844dfc8a57afe65a2c99b2",
            "placeholder": "​",
            "style": "IPY_MODEL_bdff7887011b42fca8391c87e6327460",
            "value": "8.502 MB of 8.502 MB uploaded\r"
          }
        },
        "d08ac98b1b6d448a918066a12a57ed70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d04e3b2ab6541ff8116664703d52f69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87b5223f516a4e0fa7cf19afc6ab374b",
            "value": 1
          }
        },
        "aee50054be46474c8fb9f5cd91244c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3779c15d55844dfc8a57afe65a2c99b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdff7887011b42fca8391c87e6327460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d04e3b2ab6541ff8116664703d52f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b5223f516a4e0fa7cf19afc6ab374b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcebe30561c5484e9bcf5198406d65f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7926b2fc9f34d28b0d697207374029b",
              "IPY_MODEL_18080bc51c694ed8871ec27fa5900be0",
              "IPY_MODEL_90bb833c872b4718b7f7d9d43f7150da"
            ],
            "layout": "IPY_MODEL_5d15241772d3438f9151b566b73c7632"
          }
        },
        "d7926b2fc9f34d28b0d697207374029b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa69e5e139545f798a7cbf054fd280a",
            "placeholder": "​",
            "style": "IPY_MODEL_958fd712fa7e49019b0f1796b7a399ba",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "18080bc51c694ed8871ec27fa5900be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef3fc6cb23f54ce782532a61b4cad306",
            "max": 2193720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c35e09d03865475c8a04088d48b454fb",
            "value": 2193720
          }
        },
        "90bb833c872b4718b7f7d9d43f7150da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e728f5d9cf4acf897aefcd24be9abc",
            "placeholder": "​",
            "style": "IPY_MODEL_89209a6536484c558c1fd9ea595e49c9",
            "value": " 2.19M/2.19M [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "5d15241772d3438f9151b566b73c7632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa69e5e139545f798a7cbf054fd280a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958fd712fa7e49019b0f1796b7a399ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef3fc6cb23f54ce782532a61b4cad306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35e09d03865475c8a04088d48b454fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81e728f5d9cf4acf897aefcd24be9abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89209a6536484c558c1fd9ea595e49c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b245451830946fdb1589d47d37153d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3927ce62907040e9887b7abf27043a7f",
              "IPY_MODEL_a7c0895556964d6cbc3feeed05f937d7",
              "IPY_MODEL_420c39782be6455093960c6cbbe793ee"
            ],
            "layout": "IPY_MODEL_9cfbbddea29b48b4819d22a0cc71f9f2"
          }
        },
        "3927ce62907040e9887b7abf27043a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e65edaea7c4643bf859c26d02d5a4e02",
            "placeholder": "​",
            "style": "IPY_MODEL_c726990ca14e436fbbba1838b8ec7815",
            "value": "adapter_config.json: 100%"
          }
        },
        "a7c0895556964d6cbc3feeed05f937d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f78d4979fca4912ba3939c68b112d08",
            "max": 641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_240c7ef1d1df415994a98923cb84a5c8",
            "value": 641
          }
        },
        "420c39782be6455093960c6cbbe793ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e965b854d35b4e81856c43f1978d841f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca43a4a24cbb4e86a7e8228245e79e24",
            "value": " 641/641 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "9cfbbddea29b48b4819d22a0cc71f9f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65edaea7c4643bf859c26d02d5a4e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c726990ca14e436fbbba1838b8ec7815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f78d4979fca4912ba3939c68b112d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240c7ef1d1df415994a98923cb84a5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e965b854d35b4e81856c43f1978d841f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca43a4a24cbb4e86a7e8228245e79e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7045bf4683436598c2ceb0ee9d0ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b44baaf8312f4e48bc835d376ace2e62",
              "IPY_MODEL_0f0559dcc9b94120924047b633d5dd11",
              "IPY_MODEL_4516fc45817e45e9ba0f8baf87be988e"
            ],
            "layout": "IPY_MODEL_d0c82c11da80441fbd209e67f08931ef"
          }
        },
        "b44baaf8312f4e48bc835d376ace2e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_262dfd1335ec41c99e9bd8ebe96446c5",
            "placeholder": "​",
            "style": "IPY_MODEL_0acb3437efbb40b18b4e84f68c38efc3",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "0f0559dcc9b94120924047b633d5dd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ccecb52c77415481c08514c45ef076",
            "max": 2193720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_726d599b2224492d9e19cc887a0ee3c3",
            "value": 2193720
          }
        },
        "4516fc45817e45e9ba0f8baf87be988e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d08a853d404cdfab9e5a2ad5dce37c",
            "placeholder": "​",
            "style": "IPY_MODEL_be2305b20cf248e7937c01b64f9c994d",
            "value": " 2.19M/2.19M [00:00&lt;00:00, 28.1MB/s]"
          }
        },
        "d0c82c11da80441fbd209e67f08931ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "262dfd1335ec41c99e9bd8ebe96446c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0acb3437efbb40b18b4e84f68c38efc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3ccecb52c77415481c08514c45ef076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "726d599b2224492d9e19cc887a0ee3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43d08a853d404cdfab9e5a2ad5dce37c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2305b20cf248e7937c01b64f9c994d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
