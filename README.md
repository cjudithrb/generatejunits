# ğŸ› ï¸ GenerateJUnit

Este repositorio estÃ¡ diseÃ±ado para la generaciÃ³n de casos de prueba unitarios en **JUnit** utilizando **Modelos de Lenguaje Grande (LLMs) Open Source**. Incluye todo el flujo de trabajo, desde la extracciÃ³n y procesamiento de datos hasta el fine-tuning, evaluaciÃ³n y almacenamiento de resultados.

---

## âœ¨ CaracterÃ­sticas Principales

- GeneraciÃ³n de casos de prueba unitarios
- Soporte para mÃºltiples modelos de lenguaje (GEMMA, LLaMA, Qwen)
- Preprocesamiento y limpieza de datos
- EvaluaciÃ³n y mÃ©tricas de rendimiento
- Compatibilidad con Google Colab

## ğŸ“‚ Estructura del Proyecto

```plaintext
generate-junit-tests/
â”œâ”€â”€ data/                # Datos para entrenamiento
â”œâ”€â”€ src/                 # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ colab/           # Scripts para Google Colab
â”‚   â”œâ”€â”€ evaluation/      # Scripts de evaluaciÃ³n y mÃ©tricas
â”‚   â”œâ”€â”€ finetuning/      # Scripts de fine-tuning
â”‚   â”‚   â”œâ”€â”€ gemma/       # ConfiguraciÃ³n de GEMMA
â”‚   â”‚   â”œâ”€â”€ llama/       # ConfiguraciÃ³n de LLaMA
â”‚   â”‚   â”œâ”€â”€ qwen/        # ConfiguraciÃ³n de Qwen
â”‚   â”œâ”€â”€ preprocessing/   # PreparaciÃ³n y limpieza de datos
â”‚   â”œâ”€â”€ results/         # Resultados generados
â”œâ”€â”€ utils/               # Utilidades generales
```

### ğŸ—‚ï¸ Carpetas y Archivos

#### `data/`  
ğŸ“¦ **Datos:** Contiene los datos base utilizados para el entrenamiento y evaluaciÃ³n de los modelos.

#### `src/`

##### `colab/`  
ğŸŒ **Colab:** Scripts y configuraciones adaptados para ejecutar el proyecto en Google Colab.

##### `evaluation/`  
ğŸ“Š **EvaluaciÃ³n:** Scripts para calcular mÃ©tricas y realizar anÃ¡lisis detallados del rendimiento de los modelos despuÃ©s del fine-tuning.

##### `finetuning/`  
ğŸ”§ **Fine-tuning:** Scripts diseÃ±ados para ajustar modelos de lenguaje como LLaMA, Qwen y GEMMA utilizando datos personalizados.

##### `gemma/`, `llama/`, `qwen/`  
ğŸ¤– **Modelos:** Contienen configuraciones y scripts especÃ­ficos para cada modelo, dependiendo de su arquitectura y necesidades.

##### `preprocessing/`  
ğŸ› ï¸ **Preprocesamiento:** Scripts para preparar y limpiar los datos en diferentes etapas:  
- **`1_extraction_dataset.py`**: Extrae datos relevantes del conjunto inicial.  
- **`2_make_dataset.py`**: Convierte los datos en un formato apto para el entrenamiento.  
- **`3_check_files.py`**: Valida los datos generados para garantizar su calidad.  
- **`4_generate_json.py`**: Transforma los datos a formato JSON.  
- **`5_merge_files.py`**: Fusiona archivos de datos para entrenamiento unificado.

##### `results/`  
ğŸ“ **Resultados:**  
- Resultados obtenidos con Qwen.
- Resultados obtenidos con LLaMA.

---

## ğŸš€ CÃ³mo Usar Este Proyecto

### 1ï¸âƒ£ **Preprocesamiento de Datos**
Ejecuta los scripts en la carpeta `preprocessing/` siguiendo este orden:  
1. `1_extraction_dataset.py`  
2. `2_make_dataset.py`  
3. `3_check_files.py`  
4. `4_generate_json.py`  
5. `5_merge_files.py`  

Esto generarÃ¡ un conjunto de datos limpio y listo para el entrenamiento.

### 2ï¸âƒ£ **Fine-Tuning del Modelo**
Ejecuta el script `5_1_fine_tuning.py` para ajustar tu modelo elegido (como LLaMA, GEMMA o Qwen) con los datos procesados.

### 3ï¸âƒ£ **EvaluaciÃ³n**
Analiza el rendimiento del modelo utilizando los scripts disponibles en la carpeta `evaluation/`.

### 4ï¸âƒ£ **EjecuciÃ³n en Google Colab**
Puedes usar los scripts en `colab/` si prefieres realizar el entrenamiento y evaluaciÃ³n en la nube.

---

## âš™ï¸ Requisitos

AsegÃºrate de tener instaladas las siguientes dependencias antes de ejecutar el proyecto:

- Python 3.8+
- Bibliotecas esenciales (incluye un archivo `requirements.txt`):
  - `transformers`
  - `datasets`
  - `torch`
  - `scikit-learn`
  - `pandas`
  - `evaluate`

Instala las dependencias con:

```bash
pip install -r requirements.txt
```

ğŸ‘©â€ğŸ’» Autor

Este proyecto fue desarrollado por [Judiht Rojas](https://github.com/cjudithrb).
