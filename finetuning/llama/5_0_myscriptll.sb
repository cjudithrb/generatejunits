#!/usr/bin/env bash
#SBATCH --job-name=jobft_llama        # Nombre del trabajo
#SBATCH --output=output_ft_llama.out   # Archivo de salida
#SBATCH --error=log_error_llama.err    # Archivo de error
#SBATCH --ntasks=1                    # Número de tareas (procesos)
#SBATCH --cpus-per-task=32             # CPUs por tarea, recomendado para carga de datos y procesamiento
#SBATCH --mem=32G                    # Memoria RAM total
#SBATCH --gres=gpu:2                  # Número de GPUs (1 o 2 dependiendo de los recursos)
#SBATCH --time=1-00:00:00             # Tiempo máximo de ejecución (días-horas:min:sec)
#SBATCH --partition=gpu               # Partición con acceso a GPU
#SBATCH --mail-type=END,FAIL          # Notificación al finalizar o si falla
#SBATCH --mail-user=EMAIL  # Email del usuario

# Login wandb
export WANDB_API_KEY="WANDB_API_KEY"
export HUGGING_FACE_HUB_TOKEN="HUGGING_FACE_HUB_TOKEN"
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export TRITON_CACHE_DIR=/home/my_project/generatejunits/tmp/triton_cache

# Verificación de claves
if [ -z "$WANDB_API_KEY" ]; then
    echo "WANDB_API_KEY no está definida, saliendo..."
    exit 1
else
    echo "WANDB_API_KEY está configurada correctamente."
fi
if [ -z "$HUGGING_FACE_HUB_TOKEN" ]; then
    echo "HUGGING_FACE_HUB_TOKEN no está definida, saliendo..."
    exit 1
fi

# Cargar módulos
ml load cuda || exit 1
ml load python3/3.10 || exit 1
python3 --version || { echo "Error al cargar Python"; exit 1; }

# Definir variables
PROJECT_DIR="/home/my_project"
VENV_DIR="$PROJECT_DIR/my_venvlla"

# Cambiar al directorio del proyecto
cd "$PROJECT_DIR" || exit 1

# Eliminar el entorno virtual si existe y crear uno nuevo
#rm -rf "$VENV_DIR"
#python3 -m venv "$VENV_DIR" || exit 1
source "$VENV_DIR/bin/activate" || exit 1

# Ejecutar script principal
cd "$PROJECT_DIR/generatejunits/src/llama/" || exit 1
python 5_1_fine_tuning_llama.py
